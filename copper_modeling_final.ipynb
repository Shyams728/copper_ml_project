{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "https://github.com/Shyams728/copper_ml_project/blob/main/copper_modeling_final.ipynb",
      "authorship_tag": "ABX9TyMuuGJIp6jpqnZx0iV3xJAU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shyams728/copper_ml_project/blob/main/copper_modeling_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Copper Industry Analysis: Price Prediction & Lead Classification\n",
        "\n",
        "## Table of Contents\n",
        "1. [Project Overview](#project-overview)\n",
        "2. [Data Loading and Initial Inspection](#data-loading)\n",
        "3. [Data Cleaning and Preprocessing](#data-cleaning)\n",
        "4. [Exploratory Data Analysis (EDA)](#eda)\n",
        "5. [Feature Engineering](#feature-engineering)\n",
        "6. [Data Preparation for Modeling](#data-preparation)\n",
        "7. [Regression: Selling Price Prediction](#regression)\n",
        "8. [Classification: Lead Outcome Prediction](#classification)\n",
        "9. [Model Evaluation and Comparison](#evaluation)\n",
        "10. [Conclusion and Recommendations](#conclusion)\n"
      ],
      "metadata": {
        "id": "9y_s6sRRWCnX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Copper Industry Analysis: Comprehensive Notebook\n",
        "##Predicting Selling Prices and Lead Outcomes (Won/Lost)"
      ],
      "metadata": {
        "id": "M2TDXNlyWT-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import all required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from scipy.stats import skew, chi2_contingency, boxcox\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, LogisticRegression\n",
        "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVR, SVC\n",
        "from xgboost import XGBRegressor, XGBClassifier\n",
        "from lightgbm import LGBMRegressor, LGBMClassifier\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "import joblib\n",
        "import pickle\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# Install missing libraries\n",
        "!pip install category_encoders\n",
        "\n",
        "# Set visualization style\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.float_format', '{:.2f}'.format)\n",
        "\n",
        "print(\"All libraries imported successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qguvktmGWJOS",
        "outputId": "345d0c05-4aa9-41b9-cb96-3ed94d348f12"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: category_encoders in /usr/local/lib/python3.12/dist-packages (2.9.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (2.2.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (1.0.2)\n",
            "Requirement already satisfied: scikit-learn>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (1.16.3)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (0.14.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.5->category_encoders) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.5->category_encoders) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.5->category_encoders) (2025.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.6.0->category_encoders) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.6.0->category_encoders) (3.6.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from statsmodels>=0.9.0->category_encoders) (25.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.5->category_encoders) (1.17.0)\n",
            "All libraries imported successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Project Overview <a name=\"project-overview\"></a>\n",
        "\n",
        "\n",
        "PROJECT OVERVIEW:\n",
        "This comprehensive analysis focuses on the copper industry dataset with two main objectives:\n",
        "1. REGRESSION: Predict selling prices based on various features\n",
        "2. CLASSIFICATION: Predict lead outcomes (Won/Lost)\n",
        "\n",
        "The dataset contains information about copper transactions including:\n",
        "- Transaction details (dates, quantities, prices)\n",
        "- Product specifications (thickness, width, item type)\n",
        "- Customer information (customer code, country, application)\n",
        "- Transaction status (Won, Lost, etc.)\n"
      ],
      "metadata": {
        "id": "UMgqW5juWlcM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Data Loading and Initial Inspection <a name=\"data-loading\"></a>\n"
      ],
      "metadata": {
        "id": "q9tdupsmXCwa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================================================\n",
        "# SECTION 1: DATA LOADING AND INITIAL INSPECTION\n",
        "# ============================================================================\n",
        "\n",
        "class DataLoader:\n",
        "    \"\"\"Handles data loading and initial inspection\"\"\"\n",
        "\n",
        "    def __init__(self, filepath=None):\n",
        "        self.filepath = filepath\n",
        "        self.df = None\n",
        "        self.raw_df = None\n",
        "\n",
        "    def load_data(self, filepath=None):\n",
        "        \"\"\"Load data from Excel file\"\"\"\n",
        "        if filepath:\n",
        "            self.filepath = filepath\n",
        "\n",
        "        try:\n",
        "            print(f\"Loading data from {self.filepath}...\")\n",
        "            self.raw_df = pd.read_excel(self.filepath)\n",
        "            self.df = self.raw_df.copy()\n",
        "            print(f\"Data loaded successfully! Shape: {self.df.shape}\")\n",
        "            return self.df\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading data: {e}\")\n",
        "            return None\n",
        "\n",
        "    def initial_inspection(self):\n",
        "        \"\"\"Perform initial data inspection\"\"\"\n",
        "        if self.df is None:\n",
        "            print(\"No data loaded!\")\n",
        "            return\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"DATA INITIAL INSPECTION\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        # Basic information\n",
        "        print(f\"\\n1. DATASET SHAPE: {self.df.shape}\")\n",
        "        print(f\"   - Rows: {self.df.shape[0]:,}\")\n",
        "        print(f\"   - Columns: {self.df.shape[1]}\")\n",
        "\n",
        "        # Column information\n",
        "        print(\"\\n2. COLUMN INFORMATION:\")\n",
        "        print(\"-\" * 40)\n",
        "        for i, col in enumerate(self.df.columns, 1):\n",
        "            dtype = self.df[col].dtype\n",
        "            unique = self.df[col].nunique()\n",
        "            print(f\"{i:2}. {col:20} | Type: {str(dtype):10} | Unique: {unique:6}\")\n",
        "\n",
        "        # Missing values\n",
        "        print(\"\\n3. MISSING VALUES:\")\n",
        "        print(\"-\" * 40)\n",
        "        missing = self.df.isnull().sum()\n",
        "        missing_pct = (missing / len(self.df)) * 100\n",
        "        missing_df = pd.DataFrame({\n",
        "            'Missing Count': missing,\n",
        "            'Missing %': missing_pct\n",
        "        })\n",
        "        print(missing_df[missing_df['Missing Count'] > 0].sort_values('Missing %', ascending=False))\n",
        "\n",
        "        # Data types summary\n",
        "        print(\"\\n4. DATA TYPES SUMMARY:\")\n",
        "        print(\"-\" * 40)\n",
        "        dtype_counts = self.df.dtypes.value_counts()\n",
        "        for dtype, count in dtype_counts.items():\n",
        "            print(f\"{dtype}: {count} columns\")\n",
        "\n",
        "        # Sample data\n",
        "        print(\"\\n5. SAMPLE DATA (First 3 rows):\")\n",
        "        print(\"-\" * 40)\n",
        "        print(self.df.head(3).T)\n",
        "\n",
        "        return self.df\n",
        "\n",
        "    def get_data_info(self):\n",
        "        \"\"\"Get detailed data information\"\"\"\n",
        "        info = {\n",
        "            'shape': self.df.shape,\n",
        "            'columns': list(self.df.columns),\n",
        "            'dtypes': self.df.dtypes.to_dict(),\n",
        "            'missing_values': self.df.isnull().sum().to_dict(),\n",
        "            'memory_usage': self.df.memory_usage(deep=True).sum() / 1024**2  # MB\n",
        "        }\n",
        "        return info\n",
        "\n",
        "# Initialize and load data\n",
        "data_loader = DataLoader()\n",
        "df = data_loader.load_data('/content/drive/MyDrive/data/Copper_Set.xlsx')  # Update with your path\n",
        "\n",
        "if df is not None:\n",
        "    data_info = data_loader.initial_inspection()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWbPsj0dXPp2",
        "outputId": "5dc31c63-72db-4f1c-99a9-c18441b88535"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data from /content/drive/MyDrive/data/Copper_Set.xlsx...\n",
            "Data loaded successfully! Shape: (181673, 14)\n",
            "\n",
            "================================================================================\n",
            "DATA INITIAL INSPECTION\n",
            "================================================================================\n",
            "\n",
            "1. DATASET SHAPE: (181673, 14)\n",
            "   - Rows: 181,673\n",
            "   - Columns: 14\n",
            "\n",
            "2. COLUMN INFORMATION:\n",
            "----------------------------------------\n",
            " 1. id                   | Type: object     | Unique: 181671\n",
            " 2. item_date            | Type: float64    | Unique:    252\n",
            " 3. quantity tons        | Type: object     | Unique: 181673\n",
            " 4. customer             | Type: float64    | Unique:   1169\n",
            " 5. country              | Type: float64    | Unique:     17\n",
            " 6. status               | Type: object     | Unique:      9\n",
            " 7. item type            | Type: object     | Unique:      7\n",
            " 8. application          | Type: float64    | Unique:     30\n",
            " 9. thickness            | Type: float64    | Unique:    594\n",
            "10. width                | Type: float64    | Unique:   1386\n",
            "11. material_ref         | Type: object     | Unique:  16563\n",
            "12. product_ref          | Type: int64      | Unique:     33\n",
            "13. delivery date        | Type: float64    | Unique:     28\n",
            "14. selling_price        | Type: float64    | Unique:   9795\n",
            "\n",
            "3. MISSING VALUES:\n",
            "----------------------------------------\n",
            "               Missing Count  Missing %\n",
            "material_ref           77919      42.89\n",
            "country                   28       0.02\n",
            "application               24       0.01\n",
            "id                         2       0.00\n",
            "status                     2       0.00\n",
            "item_date                  1       0.00\n",
            "customer                   1       0.00\n",
            "thickness                  1       0.00\n",
            "delivery date              1       0.00\n",
            "selling_price              1       0.00\n",
            "\n",
            "4. DATA TYPES SUMMARY:\n",
            "----------------------------------------\n",
            "float64: 8 columns\n",
            "object: 5 columns\n",
            "int64: 1 columns\n",
            "\n",
            "5. SAMPLE DATA (First 3 rows):\n",
            "----------------------------------------\n",
            "                                                  0  \\\n",
            "id             EC06F063-9DF0-440C-8764-0B0C05A4F6AE   \n",
            "item_date                               20210401.00   \n",
            "quantity tons                                 54.15   \n",
            "customer                                30156308.00   \n",
            "country                                       28.00   \n",
            "status                                          Won   \n",
            "item type                                         W   \n",
            "application                                   10.00   \n",
            "thickness                                      2.00   \n",
            "width                                       1500.00   \n",
            "material_ref                            DEQ1 S460MC   \n",
            "product_ref                              1670798778   \n",
            "delivery date                           20210701.00   \n",
            "selling_price                                854.00   \n",
            "\n",
            "                                                      1  \\\n",
            "id                 4E5F4B3D-DDDF-499D-AFDE-A3227EC49425   \n",
            "item_date                                   20210401.00   \n",
            "quantity tons                                    768.02   \n",
            "customer                                    30202938.00   \n",
            "country                                           25.00   \n",
            "status                                              Won   \n",
            "item type                                             W   \n",
            "application                                       41.00   \n",
            "thickness                                          0.80   \n",
            "width                                           1210.00   \n",
            "material_ref   0000000000000000000000000000000000104991   \n",
            "product_ref                                  1668701718   \n",
            "delivery date                               20210401.00   \n",
            "selling_price                                   1047.00   \n",
            "\n",
            "                                                  2  \n",
            "id             E140FF1B-2407-4C02-A0DD-780A093B1158  \n",
            "item_date                               20210401.00  \n",
            "quantity tons                                386.13  \n",
            "customer                                30153963.00  \n",
            "country                                       30.00  \n",
            "status                                          Won  \n",
            "item type                                        WI  \n",
            "application                                   28.00  \n",
            "thickness                                      0.38  \n",
            "width                                        952.00  \n",
            "material_ref                               S0380700  \n",
            "product_ref                                  628377  \n",
            "delivery date                           20210101.00  \n",
            "selling_price                                644.33  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Data Cleaning and Preprocessing <a name=\"data-cleaning\"></a>"
      ],
      "metadata": {
        "id": "smDyIpNPXoyr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================================================\n",
        "# SECTION 2: DATA CLEANING AND PREPROCESSING\n",
        "# ============================================================================\n",
        "\n",
        "class DataCleaner:\n",
        "    \"\"\"Handles all data cleaning operations\"\"\"\n",
        "\n",
        "    def __init__(self, df):\n",
        "        self.df = df.copy()\n",
        "        self.cleaning_steps = []\n",
        "\n",
        "    def clean_column_names(self):\n",
        "        \"\"\"Standardize column names\"\"\"\n",
        "        print(\"Cleaning column names...\")\n",
        "        self.df.columns = [col.strip().replace(' ', '_').lower() for col in self.df.columns]\n",
        "        # Rename specific columns for consistency\n",
        "        rename_dict = {\n",
        "            'customer': 'customer_code',\n",
        "            'country': 'country_code',\n",
        "            'status': 'leads'  # For classification task\n",
        "        }\n",
        "        self.df.rename(columns=rename_dict, inplace=True)\n",
        "        self.cleaning_steps.append('Column names standardized')\n",
        "        return self.df\n",
        "\n",
        "    def handle_missing_values(self, missing_threshold=0.5):\n",
        "        \"\"\"\n",
        "        Handle missing values based on threshold\n",
        "\n",
        "        Args:\n",
        "            missing_threshold: Drop columns with missing percentage above this threshold\n",
        "        \"\"\"\n",
        "        print(\"\\nHandling missing values...\")\n",
        "\n",
        "        # Calculate missing percentages\n",
        "        missing_pct = (self.df.isnull().sum() / len(self.df)) * 100\n",
        "\n",
        "        # Drop columns with high missing values\n",
        "        cols_to_drop = missing_pct[missing_pct > missing_threshold * 100].index.tolist()\n",
        "        if cols_to_drop:\n",
        "            print(f\"Dropping columns with >{missing_threshold*100}% missing values: {cols_to_drop}\")\n",
        "            self.df.drop(columns=cols_to_drop, inplace=True)\n",
        "            self.cleaning_steps.append(f'Dropped columns: {cols_to_drop}')\n",
        "\n",
        "        # Handle material_ref specifically (special case from analysis)\n",
        "        if 'material_ref' in self.df.columns:\n",
        "            # Count values starting with '00000'\n",
        "            starts_with_zero = self.df['material_ref'].astype(str).str.startswith('00000').sum()\n",
        "            null_count = self.df['material_ref'].isnull().sum()\n",
        "            total_unusable = starts_with_zero + null_count\n",
        "            unusable_pct = (total_unusable / len(self.df)) * 100\n",
        "\n",
        "            if unusable_pct > 50:  # More than 50% unusable\n",
        "                print(f\"material_ref has {unusable_pct:.1f}% unusable data - Dropping column\")\n",
        "                self.df.drop('material_ref', axis=1, inplace=True)\n",
        "                self.cleaning_steps.append('Dropped material_ref column')\n",
        "\n",
        "        # Drop rows with missing critical columns\n",
        "        critical_cols = ['customer_code', 'quantity_tons', 'selling_price', 'leads']\n",
        "        critical_cols = [col for col in critical_cols if col in self.df.columns]\n",
        "\n",
        "        initial_rows = len(self.df)\n",
        "        self.df.dropna(subset=critical_cols, inplace=True)\n",
        "        rows_dropped = initial_rows - len(self.df)\n",
        "\n",
        "        if rows_dropped > 0:\n",
        "            print(f\"Dropped {rows_dropped} rows with missing critical values\")\n",
        "            self.cleaning_steps.append(f'Dropped {rows_dropped} rows with missing critical values')\n",
        "\n",
        "        # Impute remaining missing values\n",
        "        print(\"\\nImputing remaining missing values...\")\n",
        "\n",
        "        # For categorical columns - use mode\n",
        "        categorical_cols = self.df.select_dtypes(include=['object', 'category']).columns\n",
        "        for col in categorical_cols:\n",
        "            if self.df[col].isnull().any():\n",
        "                mode_val = self.df[col].mode()[0]\n",
        "                self.df[col].fillna(mode_val, inplace=True)\n",
        "                print(f\"  {col}: filled with mode '{mode_val}'\")\n",
        "\n",
        "        # For numerical columns - use KNN imputer\n",
        "        numerical_cols = self.df.select_dtypes(include=['int64', 'float64']).columns\n",
        "        numerical_with_missing = [col for col in numerical_cols if self.df[col].isnull().any()]\n",
        "\n",
        "        if numerical_with_missing:\n",
        "            imputer = KNNImputer(n_neighbors=5)\n",
        "            self.df[numerical_with_missing] = imputer.fit_transform(self.df[numerical_with_missing])\n",
        "            print(f\"  Numerical columns imputed: {numerical_with_missing}\")\n",
        "\n",
        "        # Verify no missing values remain\n",
        "        remaining_missing = self.df.isnull().sum().sum()\n",
        "        if remaining_missing == 0:\n",
        "            print(\"✓ All missing values handled successfully!\")\n",
        "            self.cleaning_steps.append('All missing values imputed')\n",
        "        else:\n",
        "            print(f\"Warning: {remaining_missing} missing values still exist\")\n",
        "\n",
        "        return self.df\n",
        "\n",
        "    def handle_data_types(self):\n",
        "        \"\"\"Convert columns to appropriate data types\"\"\"\n",
        "        print(\"\\nConverting data types...\")\n",
        "\n",
        "        # Convert date columns\n",
        "        date_columns = ['item_date', 'delivery_date']\n",
        "        for col in date_columns:\n",
        "            if col in self.df.columns:\n",
        "                try:\n",
        "                    self.df[col] = pd.to_datetime(self.df[col], format='%Y%m%d', errors='coerce')\n",
        "                    print(f\"  {col}: converted to datetime\")\n",
        "                except:\n",
        "                    print(f\"  {col}: could not convert to datetime\")\n",
        "\n",
        "        # Handle quantity_tons (might have string values)\n",
        "        if 'quantity_tons' in self.df.columns:\n",
        "            try:\n",
        "                self.df['quantity_tons'] = pd.to_numeric(self.df['quantity_tons'], errors='coerce')\n",
        "                # Fill any resulting NaN with mean\n",
        "                mean_val = self.df['quantity_tons'].mean()\n",
        "                self.df['quantity_tons'].fillna(mean_val, inplace=True)\n",
        "                # Ensure non-negative\n",
        "                self.df['quantity_tons'] = self.df['quantity_tons'].abs()\n",
        "                print(f\"  quantity_tons: converted to numeric, filled missing with mean {mean_val:.2f}\")\n",
        "            except Exception as e:\n",
        "                print(f\"  Error converting quantity_tons: {e}\")\n",
        "\n",
        "        # Convert categorical columns\n",
        "        categorical_cols = ['customer_code', 'country_code', 'application', 'item_type', 'product_ref']\n",
        "        categorical_cols = [col for col in categorical_cols if col in self.df.columns]\n",
        "\n",
        "        for col in categorical_cols:\n",
        "            self.df[col] = self.df[col].astype(str)\n",
        "            self.df[col] = self.df[col].replace('\\.0$', '', regex=True)\n",
        "            print(f\"  {col}: converted to string and cleaned\")\n",
        "\n",
        "        # Convert leads (status) to categorical\n",
        "        if 'leads' in self.df.columns:\n",
        "            self.df['leads'] = self.df['leads'].astype('category')\n",
        "            print(f\"  leads: converted to category\")\n",
        "\n",
        "        self.cleaning_steps.append('Data types converted')\n",
        "        return self.df\n",
        "\n",
        "    def remove_duplicates(self):\n",
        "        \"\"\"Remove duplicate rows\"\"\"\n",
        "        initial_rows = len(self.df)\n",
        "        self.df.drop_duplicates(inplace=True)\n",
        "        duplicates_removed = initial_rows - len(self.df)\n",
        "\n",
        "        if duplicates_removed > 0:\n",
        "            print(f\"Removed {duplicates_removed} duplicate rows\")\n",
        "            self.cleaning_steps.append(f'Removed {duplicates_removed} duplicates')\n",
        "        else:\n",
        "            print(\"No duplicates found\")\n",
        "\n",
        "        return self.df\n",
        "\n",
        "    def handle_outliers_iqr(self, columns=None):\n",
        "        \"\"\"\n",
        "        Handle outliers using IQR method\n",
        "\n",
        "        Args:\n",
        "            columns: List of columns to process. If None, uses all numerical columns\n",
        "        \"\"\"\n",
        "        print(\"\\nHandling outliers using IQR method...\")\n",
        "\n",
        "        if columns is None:\n",
        "            columns = self.df.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "        outliers_info = {}\n",
        "\n",
        "        for col in columns:\n",
        "            if col in self.df.columns:\n",
        "                Q1 = self.df[col].quantile(0.25)\n",
        "                Q3 = self.df[col].quantile(0.75)\n",
        "                IQR = Q3 - Q1\n",
        "                lower_bound = Q1 - 1.5 * IQR\n",
        "                upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "                # Count outliers\n",
        "                outliers = self.df[(self.df[col] < lower_bound) | (self.df[col] > upper_bound)]\n",
        "                outlier_count = len(outliers)\n",
        "                outlier_pct = (outlier_count / len(self.df)) * 100\n",
        "\n",
        "                outliers_info[col] = {\n",
        "                    'count': outlier_count,\n",
        "                    'percentage': outlier_pct,\n",
        "                    'lower_bound': lower_bound,\n",
        "                    'upper_bound': upper_bound\n",
        "                }\n",
        "\n",
        "                if outlier_pct < 5:  # Only clip if outliers are less than 5%\n",
        "                    self.df[col] = self.df[col].clip(lower=lower_bound, upper=upper_bound)\n",
        "                    print(f\"  {col}: {outlier_count} outliers ({outlier_pct:.1f}%) - CLIPPED\")\n",
        "                else:\n",
        "                    print(f\"  {col}: {outlier_count} outliers ({outlier_pct:.1f}%) - SKIPPED (too many)\")\n",
        "\n",
        "        self.cleaning_steps.append('Outliers handled with IQR')\n",
        "        return self.df, outliers_info\n",
        "\n",
        "    def save_cleaned_data(self, filepath):\n",
        "        \"\"\"Save cleaned data to file\"\"\"\n",
        "        self.df.to_excel(filepath, index=False)\n",
        "        print(f\"\\nCleaned data saved to: {filepath}\")\n",
        "        return filepath\n",
        "\n",
        "    def get_cleaning_summary(self):\n",
        "        \"\"\"Get summary of all cleaning steps performed\"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"CLEANING PROCESS SUMMARY\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        print(f\"\\nInitial shape: {data_loader.raw_df.shape}\")\n",
        "        print(f\"Final shape: {self.df.shape}\")\n",
        "\n",
        "        print(\"\\nSteps performed:\")\n",
        "        for i, step in enumerate(self.cleaning_steps, 1):\n",
        "            print(f\"{i}. {step}\")\n",
        "\n",
        "        return {\n",
        "            'initial_shape': data_loader.raw_df.shape,\n",
        "            'final_shape': self.df.shape,\n",
        "            'steps': self.cleaning_steps\n",
        "        }\n",
        "\n",
        "# Apply data cleaning\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"STARTING DATA CLEANING PROCESS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "cleaner = DataCleaner(df)\n",
        "df = cleaner.clean_column_names()\n",
        "df = cleaner.handle_missing_values(missing_threshold=0.5)\n",
        "df = cleaner.handle_data_types()\n",
        "df = cleaner.remove_duplicates()\n",
        "df, outliers_info = cleaner.handle_outliers_iqr()\n",
        "\n",
        "# Save cleaned data\n",
        "cleaned_filepath = '/content/drive/MyDrive/data/processed_Copper_Set_cleaned.xlsx'\n",
        "cleaner.save_cleaned_data(cleaned_filepath)\n",
        "\n",
        "# Show cleaning summary\n",
        "cleaning_summary = cleaner.get_cleaning_summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caH0HZNQX6zx",
        "outputId": "2153ef34-33be-4855-c3dd-f3f717c33468"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "STARTING DATA CLEANING PROCESS\n",
            "================================================================================\n",
            "Cleaning column names...\n",
            "\n",
            "Handling missing values...\n",
            "material_ref has 55.4% unusable data - Dropping column\n",
            "Dropped 4 rows with missing critical values\n",
            "\n",
            "Imputing remaining missing values...\n",
            "  id: filled with mode '0000C421-EA3C-416C-97DE-25A04632AFF4'\n",
            "  Numerical columns imputed: ['item_date', 'country_code', 'application', 'thickness', 'delivery_date']\n",
            "✓ All missing values handled successfully!\n",
            "\n",
            "Converting data types...\n",
            "  item_date: converted to datetime\n",
            "  delivery_date: converted to datetime\n",
            "  quantity_tons: converted to numeric, filled missing with mean 5875.05\n",
            "  customer_code: converted to string and cleaned\n",
            "  country_code: converted to string and cleaned\n",
            "  application: converted to string and cleaned\n",
            "  item_type: converted to string and cleaned\n",
            "  product_ref: converted to string and cleaned\n",
            "  leads: converted to category\n",
            "No duplicates found\n",
            "\n",
            "Handling outliers using IQR method...\n",
            "  quantity_tons: 20954 outliers (11.5%) - SKIPPED (too many)\n",
            "  thickness: 13959 outliers (7.7%) - SKIPPED (too many)\n",
            "  width: 10948 outliers (6.0%) - SKIPPED (too many)\n",
            "  selling_price: 4877 outliers (2.7%) - CLIPPED\n",
            "\n",
            "Cleaned data saved to: /content/drive/MyDrive/data/processed_Copper_Set_cleaned.xlsx\n",
            "\n",
            "================================================================================\n",
            "CLEANING PROCESS SUMMARY\n",
            "================================================================================\n",
            "\n",
            "Initial shape: (181673, 14)\n",
            "Final shape: (181669, 13)\n",
            "\n",
            "Steps performed:\n",
            "1. Column names standardized\n",
            "2. Dropped material_ref column\n",
            "3. Dropped 4 rows with missing critical values\n",
            "4. All missing values imputed\n",
            "5. Data types converted\n",
            "6. Outliers handled with IQR\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Exploratory Data Analysis (EDA) <a name=\"eda\"></a>"
      ],
      "metadata": {
        "id": "jTAT7EyMYH-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# SECTION 3: EXPLORATORY DATA ANALYSIS (EDA)\n",
        "# ============================================================================\n",
        "\n",
        "class EDAnalyzer:\n",
        "    \"\"\"Performs comprehensive exploratory data analysis\"\"\"\n",
        "\n",
        "    def __init__(self, df):\n",
        "        self.df = df.copy()\n",
        "        self.numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "        self.categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "        self.insights = {}\n",
        "\n",
        "    def analyze_numerical_features(self):\n",
        "        \"\"\"Analyze numerical features with visualizations\"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"NUMERICAL FEATURE ANALYSIS\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        if not self.numerical_cols:\n",
        "            print(\"No numerical columns found!\")\n",
        "            return\n",
        "\n",
        "        num_features = len(self.numerical_cols)\n",
        "        num_rows = (num_features + 2) // 3  # Arrange in 3 columns\n",
        "\n",
        "        # Create subplots for distribution analysis\n",
        "        fig, axes = plt.subplots(num_rows, 3, figsize=(15, 4*num_rows))\n",
        "        axes = axes.flatten()\n",
        "\n",
        "        numerical_stats = {}\n",
        "\n",
        "        for idx, col in enumerate(self.numerical_cols):\n",
        "            if idx >= len(axes):\n",
        "                break\n",
        "\n",
        "            ax = axes[idx]\n",
        "            data = self.df[col].dropna()\n",
        "\n",
        "            # Histogram with KDE\n",
        "            sns.histplot(data, kde=True, ax=ax, bins=30, color='skyblue')\n",
        "            ax.set_title(f'{col}\\nDistribution', fontsize=10)\n",
        "            ax.set_xlabel('')\n",
        "            ax.set_ylabel('Frequency')\n",
        "\n",
        "            # Add statistics as text\n",
        "            stats_text = (f\"Mean: {data.mean():.2f}\\n\"\n",
        "                         f\"Std: {data.std():.2f}\\n\"\n",
        "                         f\"Skew: {data.skew():.2f}\")\n",
        "            ax.text(0.02, 0.98, stats_text, transform=ax.transAxes,\n",
        "                   fontsize=8, verticalalignment='top',\n",
        "                   bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "\n",
        "            # Store statistics\n",
        "            numerical_stats[col] = {\n",
        "                'mean': data.mean(),\n",
        "                'std': data.std(),\n",
        "                'min': data.min(),\n",
        "                'max': data.max(),\n",
        "                'skewness': data.skew(),\n",
        "                'kurtosis': data.kurtosis()\n",
        "            }\n",
        "\n",
        "        # Hide empty subplots\n",
        "        for idx in range(len(self.numerical_cols), len(axes)):\n",
        "            fig.delaxes(axes[idx])\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Create box plots for outlier visualization\n",
        "        fig, axes = plt.subplots(1, num_features, figsize=(15, 5))\n",
        "        if num_features == 1:\n",
        "            axes = [axes]\n",
        "\n",
        "        for idx, col in enumerate(self.numerical_cols):\n",
        "            if idx >= len(axes):\n",
        "                break\n",
        "\n",
        "            ax = axes[idx]\n",
        "            sns.boxplot(y=self.df[col], ax=ax, color='lightcoral')\n",
        "            ax.set_title(f'{col}\\nBox Plot', fontsize=10)\n",
        "            ax.set_ylabel('')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        self.insights['numerical_stats'] = numerical_stats\n",
        "        return numerical_stats\n",
        "\n",
        "    def analyze_categorical_features(self, max_categories=20):\n",
        "        \"\"\"Analyze categorical features\"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"CATEGORICAL FEATURE ANALYSIS\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        if not self.categorical_cols:\n",
        "            print(\"No categorical columns found!\")\n",
        "            return\n",
        "\n",
        "        categorical_stats = {}\n",
        "\n",
        "        for col in self.categorical_cols:\n",
        "            print(f\"\\n{col}:\")\n",
        "            print(\"-\" * 40)\n",
        "\n",
        "            value_counts = self.df[col].value_counts()\n",
        "            n_unique = len(value_counts)\n",
        "\n",
        "            print(f\"Unique values: {n_unique}\")\n",
        "            print(f\"Most common: {value_counts.index[0]} ({value_counts.iloc[0]:,} occurrences)\")\n",
        "            print(f\"Least common: {value_counts.index[-1]} ({value_counts.iloc[-1]:,} occurrences)\")\n",
        "\n",
        "            # Display top categories if too many\n",
        "            if n_unique > max_categories:\n",
        "                print(f\"\\nTop {max_categories} categories:\")\n",
        "                print(value_counts.head(max_categories))\n",
        "            else:\n",
        "                print(\"\\nAll categories:\")\n",
        "                print(value_counts)\n",
        "\n",
        "            # Store statistics\n",
        "            categorical_stats[col] = {\n",
        "                'n_unique': n_unique,\n",
        "                'most_common': value_counts.index[0],\n",
        "                'most_common_count': value_counts.iloc[0],\n",
        "                'least_common': value_counts.index[-1],\n",
        "                'least_common_count': value_counts.iloc[-1],\n",
        "                'entropy': stats.entropy(value_counts / value_counts.sum())\n",
        "            }\n",
        "\n",
        "            # Create visualization for columns with reasonable number of categories\n",
        "            if n_unique <= 15:\n",
        "                plt.figure(figsize=(10, 4))\n",
        "                if n_unique > 5:\n",
        "                    # Use horizontal bar for many categories\n",
        "                    ax = sns.countplot(y=col, data=self.df, order=value_counts.index)\n",
        "                    plt.title(f'Distribution of {col}')\n",
        "                    plt.xlabel('Count')\n",
        "                    plt.ylabel(col)\n",
        "                else:\n",
        "                    # Use pie chart for few categories\n",
        "                    plt.pie(value_counts.values, labels=value_counts.index, autopct='%1.1f%%')\n",
        "                    plt.title(f'Distribution of {col}')\n",
        "                plt.tight_layout()\n",
        "                plt.show()\n",
        "\n",
        "        self.insights['categorical_stats'] = categorical_stats\n",
        "        return categorical_stats\n",
        "\n",
        "    def analyze_target_variables(self):\n",
        "        \"\"\"Analyze target variables for both tasks\"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"TARGET VARIABLE ANALYSIS\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        target_analysis = {}\n",
        "\n",
        "        # Regression target: selling_price\n",
        "        if 'selling_price' in self.df.columns:\n",
        "            print(\"\\n1. REGRESSION TARGET: selling_price\")\n",
        "            print(\"-\" * 40)\n",
        "\n",
        "            target = self.df['selling_price']\n",
        "            print(f\"Range: ${target.min():,.2f} to ${target.max():,.2f}\")\n",
        "            print(f\"Mean: ${target.mean():,.2f}\")\n",
        "            print(f\"Median: ${target.median():,.2f}\")\n",
        "            print(f\"Std Dev: ${target.std():,.2f}\")\n",
        "            print(f\"Skewness: {target.skew():.2f}\")\n",
        "            print(f\"Kurtosis: {target.kurtosis():.2f}\")\n",
        "\n",
        "            # Visualization\n",
        "            fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "            # Histogram\n",
        "            sns.histplot(target, kde=True, ax=axes[0], bins=50, color='green')\n",
        "            axes[0].set_title('Distribution of Selling Price')\n",
        "            axes[0].set_xlabel('Selling Price ($)')\n",
        "            axes[0].set_ylabel('Frequency')\n",
        "\n",
        "            # Box plot\n",
        "            sns.boxplot(y=target, ax=axes[1], color='lightgreen')\n",
        "            axes[1].set_title('Selling Price - Box Plot')\n",
        "            axes[1].set_ylabel('Selling Price ($)')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "            target_analysis['selling_price'] = {\n",
        "                'min': target.min(),\n",
        "                'max': target.max(),\n",
        "                'mean': target.mean(),\n",
        "                'median': target.median(),\n",
        "                'std': target.std(),\n",
        "                'skewness': target.skew(),\n",
        "                'kurtosis': target.kurtosis()\n",
        "            }\n",
        "\n",
        "        # Classification target: leads\n",
        "        if 'leads' in self.df.columns:\n",
        "            print(\"\\n2. CLASSIFICATION TARGET: leads\")\n",
        "            print(\"-\" * 40)\n",
        "\n",
        "            target = self.df['leads']\n",
        "            value_counts = target.value_counts()\n",
        "\n",
        "            print(\"Class Distribution:\")\n",
        "            for class_name, count in value_counts.items():\n",
        "                percentage = (count / len(target)) * 100\n",
        "                print(f\"  {class_name}: {count:,} ({percentage:.1f}%)\")\n",
        "\n",
        "            # Check for class imbalance\n",
        "            imbalance_ratio = value_counts.max() / value_counts.min()\n",
        "            print(f\"\\nClass Imbalance Ratio: {imbalance_ratio:.2f}:1\")\n",
        "\n",
        "            if imbalance_ratio > 5:\n",
        "                print(\"⚠️ WARNING: Significant class imbalance detected!\")\n",
        "\n",
        "            # Visualization\n",
        "            fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "            # Count plot\n",
        "            sns.countplot(x=target, ax=axes[0], palette='Set2')\n",
        "            axes[0].set_title('Distribution of Lead Outcomes')\n",
        "            axes[0].set_xlabel('Lead Outcome')\n",
        "            axes[0].set_ylabel('Count')\n",
        "\n",
        "            # Pie chart\n",
        "            axes[1].pie(value_counts.values, labels=value_counts.index,\n",
        "                       autopct='%1.1f%%', colors=sns.color_palette('Set2'))\n",
        "            axes[1].set_title('Lead Outcomes - Percentage Distribution')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "            target_analysis['leads'] = {\n",
        "                'class_distribution': value_counts.to_dict(),\n",
        "                'imbalance_ratio': imbalance_ratio,\n",
        "                'majority_class': value_counts.idxmax(),\n",
        "                'minority_class': value_counts.idxmin()\n",
        "            }\n",
        "\n",
        "        self.insights['target_analysis'] = target_analysis\n",
        "        return target_analysis\n",
        "\n",
        "    def correlation_analysis(self):\n",
        "        \"\"\"Perform correlation analysis\"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"CORRELATION ANALYSIS\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        # Select only numerical columns for correlation\n",
        "        numerical_df = self.df.select_dtypes(include=[np.number])\n",
        "\n",
        "        if len(numerical_df.columns) < 2:\n",
        "            print(\"Not enough numerical columns for correlation analysis\")\n",
        "            return\n",
        "\n",
        "        # Calculate correlation matrix\n",
        "        corr_matrix = numerical_df.corr()\n",
        "\n",
        "        # Plot heatmap\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
        "        sns.heatmap(corr_matrix, mask=mask, annot=True, fmt='.2f',\n",
        "                   cmap='coolwarm', center=0, square=True)\n",
        "        plt.title('Correlation Matrix of Numerical Features')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Find strong correlations\n",
        "        print(\"\\nStrong Correlations (|r| > 0.7):\")\n",
        "        strong_corrs = []\n",
        "        for i in range(len(corr_matrix.columns)):\n",
        "            for j in range(i+1, len(corr_matrix.columns)):\n",
        "                corr_val = corr_matrix.iloc[i, j]\n",
        "                if abs(corr_val) > 0.7:\n",
        "                    col1, col2 = corr_matrix.columns[i], corr_matrix.columns[j]\n",
        "                    strong_corrs.append((col1, col2, corr_val))\n",
        "                    print(f\"  {col1} - {col2}: {corr_val:.3f}\")\n",
        "\n",
        "        if not strong_corrs:\n",
        "            print(\"  No strong correlations found\")\n",
        "\n",
        "        # Analyze correlation with target variables\n",
        "        print(\"\\nCorrelation with Target Variables:\")\n",
        "\n",
        "        if 'selling_price' in numerical_df.columns:\n",
        "            target_corr = corr_matrix['selling_price'].drop('selling_price').sort_values(key=abs, ascending=False)\n",
        "            print(\"\\nTop correlations with selling_price:\")\n",
        "            for col, corr in target_corr.head(10).items():\n",
        "                print(f\"  {col}: {corr:.3f}\")\n",
        "\n",
        "        self.insights['correlation_matrix'] = corr_matrix\n",
        "        self.insights['strong_correlations'] = strong_corrs\n",
        "\n",
        "        return corr_matrix\n",
        "\n",
        "    def time_series_analysis(self):\n",
        "        \"\"\"Analyze temporal patterns if date columns exist\"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"TIME SERIES ANALYSIS\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        date_columns = [col for col in self.df.columns if 'date' in col.lower()]\n",
        "\n",
        "        if not date_columns:\n",
        "            print(\"No date columns found for time series analysis\")\n",
        "            return\n",
        "\n",
        "        time_insights = {}\n",
        "\n",
        "        for date_col in date_columns:\n",
        "            print(f\"\\nAnalyzing {date_col}...\")\n",
        "\n",
        "            # Ensure it's datetime\n",
        "            if not pd.api.types.is_datetime64_any_dtype(self.df[date_col]):\n",
        "                print(f\"  {date_col} is not datetime - skipping\")\n",
        "                continue\n",
        "\n",
        "            # Extract temporal features\n",
        "            self.df[f'{date_col}_year'] = self.df[date_col].dt.year\n",
        "            self.df[f'{date_col}_month'] = self.df[date_col].dt.month\n",
        "            self.df[f'{date_col}_quarter'] = self.df[date_col].dt.quarter\n",
        "            self.df[f'{date_col}_dayofweek'] = self.df[date_col].dt.dayofweek\n",
        "\n",
        "            # Analyze trends\n",
        "            fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "            axes = axes.flatten()\n",
        "\n",
        "            # Monthly sales trend\n",
        "            monthly_sales = self.df.groupby(f'{date_col}_month')['quantity_tons'].sum()\n",
        "            axes[0].plot(monthly_sales.index, monthly_sales.values, marker='o', color='blue')\n",
        "            axes[0].set_title(f'Monthly Sales Trend ({date_col})')\n",
        "            axes[0].set_xlabel('Month')\n",
        "            axes[0].set_ylabel('Quantity (tons)')\n",
        "            axes[0].grid(True)\n",
        "\n",
        "            # Price by month\n",
        "            monthly_price = self.df.groupby(f'{date_col}_month')['selling_price'].mean()\n",
        "            axes[1].plot(monthly_price.index, monthly_price.values, marker='s', color='green')\n",
        "            axes[1].set_title(f'Average Price by Month ({date_col})')\n",
        "            axes[1].set_xlabel('Month')\n",
        "            axes[1].set_ylabel('Average Selling Price')\n",
        "            axes[1].grid(True)\n",
        "\n",
        "            # Sales by day of week\n",
        "            dow_sales = self.df.groupby(f'{date_col}_dayofweek')['quantity_tons'].sum()\n",
        "            days = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
        "            axes[2].bar(range(len(days)), dow_sales.values, color='orange')\n",
        "            axes[2].set_title(f'Sales by Day of Week ({date_col})')\n",
        "            axes[2].set_xlabel('Day of Week')\n",
        "            axes[2].set_ylabel('Quantity (tons)')\n",
        "            axes[2].set_xticks(range(len(days)))\n",
        "            axes[2].set_xticklabels(days)\n",
        "\n",
        "            # Quarterly analysis\n",
        "            quarterly_sales = self.df.groupby(f'{date_col}_quarter')['quantity_tons'].sum()\n",
        "            axes[3].bar(quarterly_sales.index, quarterly_sales.values, color='purple')\n",
        "            axes[3].set_title(f'Quarterly Sales ({date_col})')\n",
        "            axes[3].set_xlabel('Quarter')\n",
        "            axes[3].set_ylabel('Quantity (tons)')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "            time_insights[date_col] = {\n",
        "                'monthly_sales': monthly_sales.to_dict(),\n",
        "                'monthly_price': monthly_price.to_dict(),\n",
        "                'dow_sales': dow_sales.to_dict(),\n",
        "                'quarterly_sales': quarterly_sales.to_dict()\n",
        "            }\n",
        "\n",
        "        self.insights['time_analysis'] = time_insights\n",
        "        return time_insights\n",
        "\n",
        "    def generate_eda_report(self):\n",
        "        \"\"\"Generate comprehensive EDA report\"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"COMPREHENSIVE EDA REPORT\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        # Execute all analyses\n",
        "        self.analyze_numerical_features()\n",
        "        self.analyze_categorical_features()\n",
        "        self.analyze_target_variables()\n",
        "        self.correlation_analysis()\n",
        "        self.time_series_analysis()\n",
        "\n",
        "        # Summary insights\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"KEY INSIGHTS SUMMARY\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        summary = {\n",
        "            'dataset_shape': self.df.shape,\n",
        "            'numerical_features': len(self.numerical_cols),\n",
        "            'categorical_features': len(self.categorical_cols),\n",
        "            'total_samples': len(self.df),\n",
        "            'missing_values': self.df.isnull().sum().sum()\n",
        "        }\n",
        "\n",
        "        for key, value in summary.items():\n",
        "            print(f\"{key.replace('_', ' ').title()}: {value}\")\n",
        "\n",
        "        # Add recommendations based on insights\n",
        "        print(\"\\nRECOMMENDATIONS:\")\n",
        "\n",
        "        if 'target_analysis' in self.insights:\n",
        "            if 'leads' in self.insights['target_analysis']:\n",
        "                imbalance = self.insights['target_analysis']['leads']['imbalance_ratio']\n",
        "                if imbalance > 5:\n",
        "                    print(\"1. Address class imbalance for classification using SMOTE or class weights\")\n",
        "\n",
        "        if 'numerical_stats' in self.insights:\n",
        "            for col, stats in self.insights['numerical_stats'].items():\n",
        "                if abs(stats['skewness']) > 1:\n",
        "                    print(f\"2. Consider transforming {col} (skewness: {stats['skewness']:.2f})\")\n",
        "\n",
        "        return self.insights\n",
        "\n",
        "# Perform comprehensive EDA\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"STARTING EXPLORATORY DATA ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFnMMenSYVRW",
        "outputId": "13fc57f8-a53c-478b-a914-46c480eaab3e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "STARTING EXPLORATORY DATA ANALYSIS\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel(r'/content/drive/MyDrive/data/processed_Copper_Set_cleaned.xlsx')\n",
        "eda = EDAnalyzer(df)\n",
        "eda_insights = eda.generate_eda_report()"
      ],
      "metadata": {
        "id": "zXlBX0ZpaLfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Feature Engineering <a name=\"feature-engineering\"></a>"
      ],
      "metadata": {
        "id": "VKrAACnQY3uC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# SECTION 4: FEATURE ENGINEERING\n",
        "# ============================================================================\n",
        "\n",
        "class FeatureEngineer:\n",
        "    \"\"\"Handles feature engineering and transformation\"\"\"\n",
        "\n",
        "    def __init__(self, df):\n",
        "        self.df = df.copy()\n",
        "        self.transformations = {}\n",
        "\n",
        "    def handle_skewness(self, skew_threshold=0.5):\n",
        "        \"\"\"Transform skewed features\"\"\"\n",
        "        print(\"\\nHandling feature skewness...\")\n",
        "\n",
        "        numerical_cols = self.df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "        # Remove target columns from transformation\n",
        "        if 'selling_price' in numerical_cols:\n",
        "            numerical_cols.remove('selling_price')\n",
        "\n",
        "        skewed_features = {}\n",
        "        transformed_features = {}\n",
        "\n",
        "        for col in numerical_cols:\n",
        "            data = self.df[col].dropna()\n",
        "            col_skew = skew(data)\n",
        "\n",
        "            if abs(col_skew) > skew_threshold:\n",
        "                skewed_features[col] = col_skew\n",
        "\n",
        "                # Apply appropriate transformation\n",
        "                if col_skew > 0:  # Right skewed\n",
        "                    # Try log transformation\n",
        "                    if (data > 0).all():\n",
        "                        transformed = np.log1p(data)\n",
        "                        transform_type = 'log'\n",
        "                    else:\n",
        "                        # Use box-cox if negative values exist\n",
        "                        transformed, _ = boxcox(data - data.min() + 1)\n",
        "                        transform_type = 'boxcox'\n",
        "                else:  # Left skewed\n",
        "                    # Try square transformation for left skew\n",
        "                    transformed = np.power(data - data.min() + 1, 2)\n",
        "                    transform_type = 'square'\n",
        "\n",
        "                # Calculate new skewness\n",
        "                new_skew = skew(transformed)\n",
        "                improvement = abs(col_skew) - abs(new_skew)\n",
        "\n",
        "                # Only apply if improvement is significant\n",
        "                if improvement > 0.1:\n",
        "                    self.df[f'transformed_{col}'] = transformed\n",
        "                    transformed_features[col] = {\n",
        "                        'original_skew': col_skew,\n",
        "                        'new_skew': new_skew,\n",
        "                        'improvement': improvement,\n",
        "                        'transform_type': transform_type\n",
        "                    }\n",
        "                    print(f\"  {col}: {col_skew:.2f} → {new_skew:.2f} ({transform_type})\")\n",
        "\n",
        "        print(f\"\\nTransformed {len(transformed_features)} features\")\n",
        "        self.transformations['skewness'] = transformed_features\n",
        "        return self.df\n",
        "\n",
        "    def create_temporal_features(self):\n",
        "        \"\"\"Create features from date columns\"\"\"\n",
        "        print(\"\\nCreating temporal features...\")\n",
        "\n",
        "        date_columns = [col for col in self.df.columns if 'date' in col.lower() and pd.api.types.is_datetime64_any_dtype(self.df[col])]\n",
        "\n",
        "        temporal_features = {}\n",
        "\n",
        "        for date_col in date_columns:\n",
        "            # Basic temporal features\n",
        "            self.df[f'{date_col}_year'] = self.df[date_col].dt.year\n",
        "            self.df[f'{date_col}_month'] = self.df[date_col].dt.month\n",
        "            self.df[f'{date_col}_day'] = self.df[date_col].dt.day\n",
        "            self.df[f'{date_col}_dayofweek'] = self.df[date_col].dt.dayofweek\n",
        "            self.df[f'{date_col}_quarter'] = self.df[date_col].dt.quarter\n",
        "            self.df[f'{date_col}_is_weekend'] = self.df[date_col].dt.dayofweek.isin([5, 6]).astype(int)\n",
        "\n",
        "            # Cyclical encoding for month and dayofweek\n",
        "            self.df[f'{date_col}_month_sin'] = np.sin(2 * np.pi * self.df[f'{date_col}_month'] / 12)\n",
        "            self.df[f'{date_col}_month_cos'] = np.cos(2 * np.pi * self.df[f'{date_col}_month'] / 12)\n",
        "            self.df[f'{date_col}_dayofweek_sin'] = np.sin(2 * np.pi * self.df[f'{date_col}_dayofweek'] / 7)\n",
        "            self.df[f'{date_col}_dayofweek_cos'] = np.cos(2 * np.pi * self.df[f'{date_col}_dayofweek'] / 7)\n",
        "\n",
        "            print(f\"  {date_col}: Created 10 temporal features\")\n",
        "            temporal_features[date_col] = 10\n",
        "\n",
        "        # Create lead time if both item and delivery dates exist\n",
        "        if 'item_date' in date_columns and 'delivery_date' in date_columns:\n",
        "            self.df['lead_time_days'] = (self.df['delivery_date'] - self.df['item_date']).dt.days\n",
        "            self.df['lead_time_weeks'] = self.df['lead_time_days'] / 7\n",
        "            self.df['lead_time_months'] = self.df['lead_time_days'] / 30\n",
        "\n",
        "            # Handle any negative lead times\n",
        "            negative_mask = self.df['lead_time_days'] < 0\n",
        "            if negative_mask.any():\n",
        "                print(f\"  Found {negative_mask.sum()} negative lead times - setting to NaN\")\n",
        "                self.df.loc[negative_mask, ['lead_time_days', 'lead_time_weeks', 'lead_time_months']] = np.nan\n",
        "\n",
        "            print(\"  Created lead time features\")\n",
        "            temporal_features['lead_time'] = 3\n",
        "\n",
        "        # Drop original date columns after creating temporal features\n",
        "        if date_columns:\n",
        "            self.df.drop(columns=date_columns, inplace=True)\n",
        "            print(f\"  Dropped original date columns: {date_columns}\")\n",
        "\n",
        "        self.transformations['temporal'] = temporal_features\n",
        "        return self.df\n",
        "\n",
        "    def create_interaction_features(self):\n",
        "        \"\"\"Create interaction features between important variables\"\"\"\n",
        "        print(\"\\nCreating interaction features...\")\n",
        "\n",
        "        interaction_features = []\n",
        "\n",
        "        # Product-related interactions\n",
        "        if all(col in self.df.columns for col in ['quantity_tons', 'selling_price']):\n",
        "            self.df['total_value'] = self.df['quantity_tons'] * self.df['selling_price']\n",
        "            interaction_features.append('total_value')\n",
        "\n",
        "        if all(col in self.df.columns for col in ['thickness', 'width']):\n",
        "            self.df['area_approx'] = self.df['thickness'] * self.df['width']\n",
        "            interaction_features.append('area_approx')\n",
        "\n",
        "        # Customer frequency (if customer_code exists)\n",
        "        if 'customer_code' in self.df.columns:\n",
        "            customer_freq = self.df['customer_code'].value_counts()\n",
        "            self.df['customer_frequency'] = self.df['customer_code'].map(customer_freq)\n",
        "            interaction_features.append('customer_frequency')\n",
        "\n",
        "        # Price per unit features\n",
        "        if all(col in self.df.columns for col in ['selling_price', 'quantity_tons']):\n",
        "            mask = self.df['quantity_tons'] > 0\n",
        "            self.df['price_per_ton'] = np.where(mask,\n",
        "                                               self.df['selling_price'] / self.df['quantity_tons'],\n",
        "                                               np.nan)\n",
        "            interaction_features.append('price_per_ton')\n",
        "\n",
        "        print(f\"  Created {len(interaction_features)} interaction features: {interaction_features}\")\n",
        "        self.transformations['interactions'] = interaction_features\n",
        "        return self.df\n",
        "\n",
        "    def encode_categorical_features(self, encoding_strategy='auto'):\n",
        "        \"\"\"\n",
        "        Encode categorical features\n",
        "\n",
        "        Args:\n",
        "            encoding_strategy: 'auto', 'onehot', 'target', 'frequency', 'ordinal'\n",
        "        \"\"\"\n",
        "        print(\"\\nEncoding categorical features...\")\n",
        "\n",
        "        categorical_cols = self.df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "\n",
        "        # Remove target if present\n",
        "        if 'leads' in categorical_cols:\n",
        "            categorical_cols.remove('leads')\n",
        "\n",
        "        if not categorical_cols:\n",
        "            print(\"  No categorical columns to encode\")\n",
        "            return self.df\n",
        "\n",
        "        encoding_results = {}\n",
        "\n",
        "        for col in categorical_cols:\n",
        "            n_unique = self.df[col].nunique()\n",
        "\n",
        "            if encoding_strategy == 'auto':\n",
        "                # Auto strategy based on cardinality\n",
        "                if n_unique <= 10:\n",
        "                    encode_method = 'onehot'\n",
        "                elif n_unique <= 50:\n",
        "                    encode_method = 'target'\n",
        "                else:\n",
        "                    encode_method = 'frequency'\n",
        "            else:\n",
        "                encode_method = encoding_strategy\n",
        "\n",
        "            # Apply encoding\n",
        "            if encode_method == 'onehot':\n",
        "                # One-hot encoding for low cardinality\n",
        "                dummies = pd.get_dummies(self.df[col], prefix=col, drop_first=True)\n",
        "                self.df = pd.concat([self.df, dummies], axis=1)\n",
        "                encoding_results[col] = {'method': 'onehot', 'new_columns': len(dummies.columns)}\n",
        "\n",
        "            elif encode_method == 'target':\n",
        "                # Target encoding (to be applied after train-test split)\n",
        "                print(f\"  {col}: Will use target encoding during modeling (high cardinality: {n_unique})\")\n",
        "                encoding_results[col] = {'method': 'target', 'cardinality': n_unique}\n",
        "\n",
        "            elif encode_method == 'frequency':\n",
        "                # Frequency encoding\n",
        "                freq_map = self.df[col].value_counts() / len(self.df)\n",
        "                self.df[f'{col}_freq'] = self.df[col].map(freq_map)\n",
        "                encoding_results[col] = {'method': 'frequency'}\n",
        "\n",
        "            elif encode_method == 'ordinal':\n",
        "                # Ordinal encoding based on target mean (to be applied after split)\n",
        "                print(f\"  {col}: Will use ordinal encoding during modeling\")\n",
        "                encoding_results[col] = {'method': 'ordinal', 'cardinality': n_unique}\n",
        "\n",
        "            print(f\"  {col}: {n_unique} unique values → {encode_method}\")\n",
        "\n",
        "        # Drop original categorical columns if one-hot encoded\n",
        "        cols_to_drop = [col for col, info in encoding_results.items()\n",
        "                       if info['method'] in ['onehot', 'frequency']]\n",
        "        if cols_to_drop:\n",
        "            self.df.drop(columns=cols_to_drop, inplace=True)\n",
        "\n",
        "        self.transformations['encoding'] = encoding_results\n",
        "        return self.df\n",
        "\n",
        "    def scale_features(self, method='standard'):\n",
        "        \"\"\"Scale numerical features (to be applied after train-test split)\"\"\"\n",
        "        print(f\"\\nSetting up {method} scaling...\")\n",
        "\n",
        "        numerical_cols = self.df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "        # Remove target columns\n",
        "        if 'selling_price' in numerical_cols:\n",
        "            numerical_cols.remove('selling_price')\n",
        "        if 'leads' in numerical_cols:\n",
        "            numerical_cols.remove('leads')\n",
        "\n",
        "        print(f\"  Will scale {len(numerical_cols)} numerical features during modeling\")\n",
        "        self.transformations['scaling'] = {\n",
        "            'method': method,\n",
        "            'columns': numerical_cols\n",
        "        }\n",
        "\n",
        "        return self.df\n",
        "\n",
        "    def perform_dimensionality_reduction(self, n_components=None):\n",
        "        \"\"\"Set up PCA for dimensionality reduction\"\"\"\n",
        "        print(\"\\nSetting up dimensionality reduction...\")\n",
        "\n",
        "        # Count total features\n",
        "        total_features = len(self.df.columns)\n",
        "        numerical_features = len(self.df.select_dtypes(include=[np.number]).columns)\n",
        "\n",
        "        if n_components is None:\n",
        "            # Auto-determine based on feature count\n",
        "            if total_features > 50:\n",
        "                n_components = min(50, int(total_features * 0.7))\n",
        "            else:\n",
        "                n_components = total_features\n",
        "\n",
        "        print(f\"  Total features: {total_features}\")\n",
        "        print(f\"  Numerical features: {numerical_features}\")\n",
        "        print(f\"  Will apply PCA with {n_components} components during modeling\")\n",
        "\n",
        "        self.transformations['pca'] = {\n",
        "            'n_components': n_components,\n",
        "            'total_features': total_features\n",
        "        }\n",
        "\n",
        "        return self.df\n",
        "\n",
        "    def get_feature_summary(self):\n",
        "        \"\"\"Get summary of all feature engineering steps\"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"FEATURE ENGINEERING SUMMARY\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        print(f\"\\nOriginal shape: {eda.df.shape}\")\n",
        "        print(f\"Current shape: {self.df.shape}\")\n",
        "\n",
        "        print(\"\\nTransformations applied:\")\n",
        "        for transform_type, details in self.transformations.items():\n",
        "            print(f\"\\n{transform_type.upper()}:\")\n",
        "            if isinstance(details, dict):\n",
        "                for key, value in details.items():\n",
        "                    if isinstance(value, dict):\n",
        "                        print(f\"  {key}:\")\n",
        "                        for subkey, subvalue in value.items():\n",
        "                            print(f\"    {subkey}: {subvalue}\")\n",
        "                    else:\n",
        "                        print(f\"  {key}: {value}\")\n",
        "            else:\n",
        "                print(f\"  {details}\")\n",
        "\n",
        "        # Feature counts by type\n",
        "        numerical = len(self.df.select_dtypes(include=[np.number]).columns)\n",
        "        categorical = len(self.df.select_dtypes(include=['object', 'category']).columns)\n",
        "\n",
        "        print(f\"\\nFeature counts:\")\n",
        "        print(f\"  Numerical: {numerical}\")\n",
        "        print(f\"  Categorical: {categorical}\")\n",
        "        print(f\"  Total: {numerical + categorical}\")\n",
        "\n",
        "        return {\n",
        "            'final_shape': self.df.shape,\n",
        "            'transformations': self.transformations,\n",
        "            'feature_counts': {'numerical': numerical, 'categorical': categorical}\n",
        "        }\n",
        "\n",
        "# Apply feature engineering\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"STARTING FEATURE ENGINEERING\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "feature_engineer = FeatureEngineer(df)\n",
        "df = feature_engineer.handle_skewness(skew_threshold=0.5)\n",
        "df = feature_engineer.create_temporal_features()\n",
        "df = feature_engineer.create_interaction_features()\n",
        "df = feature_engineer.encode_categorical_features(encoding_strategy='auto')\n",
        "df = feature_engineer.scale_features(method='standard')\n",
        "df = feature_engineer.perform_dimensionality_reduction(n_components=32)\n",
        "\n",
        "# Get feature engineering summary\n",
        "feature_summary = feature_engineer.get_feature_summary()"
      ],
      "metadata": {
        "id": "bSjPBHUHZCwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Data Preparation for Modeling <a name=\"data-preparation\"></a>"
      ],
      "metadata": {
        "id": "h-lKBKlnZW48"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================\n",
        "# SECTION 5: DATA PREPARATION FOR MODELING\n",
        "# =========================================\n",
        "\n",
        "class DataPreparer:\n",
        "    \"\"\"Prepares data for machine learning modeling with proper NaN handling\"\"\"\n",
        "\n",
        "    def __init__(self, df):\n",
        "        self.df = df.copy()\n",
        "        self.X_train_reg = None\n",
        "        self.X_test_reg = None\n",
        "        self.y_train_reg = None\n",
        "        self.y_test_reg = None\n",
        "        self.X_train_cls = None\n",
        "        self.X_test_cls = None\n",
        "        self.y_train_cls = None\n",
        "        self.y_test_cls = None\n",
        "        self.preprocessing_info = {}\n",
        "\n",
        "    def prepare_regression_data(self, target_col='selling_price', test_size=0.2, random_state=42):\n",
        "        \"\"\"Prepare data for regression task\"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"PREPARING REGRESSION DATA\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        # Separate features and target\n",
        "        X = self.df.drop(columns=[target_col, 'leads'] if 'leads' in self.df.columns else [target_col])\n",
        "        y = self.df[target_col]\n",
        "\n",
        "        print(f\"Features shape: {X.shape}\")\n",
        "        print(f\"Target shape: {y.shape}\")\n",
        "\n",
        "        # Check for NaN in target\n",
        "        nan_in_target = y.isna().sum()\n",
        "        if nan_in_target > 0:\n",
        "            print(f\"Warning: {nan_in_target} NaN values in target - removing them\")\n",
        "            mask = y.notna()\n",
        "            X = X[mask]\n",
        "            y = y[mask]\n",
        "            print(f\"After removing NaN in target: X={X.shape}, y={y.shape}\")\n",
        "\n",
        "        # Identify categorical columns that need target encoding\n",
        "        categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "        numerical_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "        print(f\"\\nCategorical columns for target encoding: {len(categorical_cols)}\")\n",
        "        print(f\"Numerical columns: {len(numerical_cols)}\")\n",
        "\n",
        "        # Split data\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=test_size, random_state=random_state\n",
        "        )\n",
        "\n",
        "        print(f\"\\nTrain set: {X_train.shape}\")\n",
        "        print(f\"Test set: {X_test.shape}\")\n",
        "\n",
        "        # Store splits\n",
        "        self.X_train_reg = X_train\n",
        "        self.X_test_reg = X_test\n",
        "        self.y_train_reg = y_train\n",
        "        self.y_test_reg = y_test\n",
        "\n",
        "        # Store preprocessing info\n",
        "        self.preprocessing_info['regression'] = {\n",
        "            'categorical_cols': categorical_cols,\n",
        "            'numerical_cols': numerical_cols,\n",
        "            'target_col': target_col,\n",
        "            'train_shape': X_train.shape,\n",
        "            'test_shape': X_test.shape\n",
        "        }\n",
        "\n",
        "        return X_train, X_test, y_train, y_test\n",
        "\n",
        "    def prepare_classification_data(self, target_col='leads', test_size=0.2, random_state=42):\n",
        "        \"\"\"Prepare data for classification task\"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"PREPARING CLASSIFICATION DATA\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        # Separate features and target\n",
        "        X = self.df.drop(columns=[target_col, 'selling_price'] if 'selling_price' in self.df.columns else [target_col])\n",
        "        y = self.df[target_col]\n",
        "\n",
        "        # Convert target to binary if needed\n",
        "        if y.nunique() > 2:\n",
        "            print(\"Multi-class classification detected\")\n",
        "            # For simplicity, keep only Won and Lost if they exist\n",
        "            if set(['Won', 'Lost']).issubset(set(y.unique())):\n",
        "                mask = y.isin(['Won', 'Lost'])\n",
        "                X = X[mask]\n",
        "                y = y[mask]\n",
        "                y = (y == 'Won').astype(int)  # Convert to binary\n",
        "                print(\"Converted to binary classification (Won=1, Lost=0)\")\n",
        "\n",
        "        # Check for NaN in target\n",
        "        nan_in_target = y.isna().sum()\n",
        "        if nan_in_target > 0:\n",
        "            print(f\"Warning: {nan_in_target} NaN values in target - removing them\")\n",
        "            mask = y.notna()\n",
        "            X = X[mask]\n",
        "            y = y[mask]\n",
        "            print(f\"After removing NaN in target: X={X.shape}, y={y.shape}\")\n",
        "\n",
        "        print(f\"Features shape: {X.shape}\")\n",
        "        print(f\"Target shape: {y.shape}\")\n",
        "\n",
        "        # Check class distribution\n",
        "        class_dist = y.value_counts()\n",
        "        print(f\"\\nClass distribution:\")\n",
        "        for class_val, count in class_dist.items():\n",
        "            percentage = (count / len(y)) * 100\n",
        "            print(f\"  Class {class_val}: {count} samples ({percentage:.1f}%)\")\n",
        "\n",
        "        # Split data\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=test_size, random_state=random_state, stratify=y\n",
        "        )\n",
        "\n",
        "        print(f\"\\nTrain set: {X_train.shape}\")\n",
        "        print(f\"Test set: {X_test.shape}\")\n",
        "\n",
        "        # Store splits\n",
        "        self.X_train_cls = X_train\n",
        "        self.X_test_cls = X_test\n",
        "        self.y_train_cls = y_train\n",
        "        self.y_test_cls = y_test\n",
        "\n",
        "        # Store preprocessing info\n",
        "        self.preprocessing_info['classification'] = {\n",
        "            'class_distribution': class_dist.to_dict(),\n",
        "            'train_shape': X_train.shape,\n",
        "            'test_shape': X_test.shape,\n",
        "            'is_binary': y.nunique() == 2\n",
        "        }\n",
        "\n",
        "        return X_train, X_test, y_train, y_test\n",
        "\n",
        "    def handle_class_imbalance(self, method='smote', random_state=42):\n",
        "        \"\"\"Handle class imbalance for classification\"\"\"\n",
        "        print(f\"\\nHandling class imbalance using {method.upper()}...\")\n",
        "\n",
        "        if self.X_train_cls is None or self.y_train_cls is None:\n",
        "            print(\"Classification data not prepared yet!\")\n",
        "            return None, None\n",
        "\n",
        "        # Check if imbalance exists\n",
        "        class_counts = self.y_train_cls.value_counts()\n",
        "        imbalance_ratio = class_counts.max() / class_counts.min()\n",
        "\n",
        "        print(f\"Class imbalance ratio: {imbalance_ratio:.2f}:1\")\n",
        "\n",
        "        if imbalance_ratio < 1.5:\n",
        "            print(\"No significant class imbalance detected\")\n",
        "            return self.X_train_cls, self.y_train_cls\n",
        "\n",
        "        # Apply balancing method\n",
        "        if method.lower() == 'smote':\n",
        "            balancer = SMOTE(random_state=random_state)\n",
        "        elif method.lower() == 'oversample':\n",
        "            balancer = RandomOverSampler(random_state=random_state)\n",
        "        elif method.lower() == 'undersample':\n",
        "            balancer = RandomUnderSampler(random_state=random_state)\n",
        "        else:\n",
        "            print(f\"Unknown method: {method}. Using SMOTE.\")\n",
        "            balancer = SMOTE(random_state=random_state)\n",
        "\n",
        "        X_resampled, y_resampled = balancer.fit_resample(self.X_train_cls, self.y_train_cls)\n",
        "\n",
        "        print(f\"Before balancing: {self.X_train_cls.shape[0]} samples\")\n",
        "        print(f\"After balancing: {X_resampled.shape[0]} samples\")\n",
        "\n",
        "        # Update training data\n",
        "        self.X_train_cls = X_resampled\n",
        "        self.y_train_cls = y_resampled\n",
        "\n",
        "        # Store balancing info\n",
        "        self.preprocessing_info['classification']['balancing_method'] = method\n",
        "        self.preprocessing_info['classification']['resampled_shape'] = X_resampled.shape\n",
        "\n",
        "        return X_resampled, y_resampled\n",
        "\n",
        "    def apply_preprocessing_pipeline(self, task='regression'):\n",
        "        \"\"\"Apply complete preprocessing pipeline with proper NaN handling\"\"\"\n",
        "        print(f\"\\nApplying preprocessing pipeline for {task}...\")\n",
        "\n",
        "        if task == 'regression':\n",
        "            X_train = self.X_train_reg.copy()\n",
        "            X_test = self.X_test_reg.copy()\n",
        "            y_train = self.y_train_reg\n",
        "\n",
        "            # Get categorical columns info\n",
        "            cat_cols = self.preprocessing_info['regression']['categorical_cols']\n",
        "            num_cols = self.preprocessing_info['regression']['numerical_cols']\n",
        "\n",
        "        elif task == 'classification':\n",
        "            X_train = self.X_train_cls.copy()\n",
        "            X_test = self.X_test_cls.copy()\n",
        "            y_train = self.y_train_cls\n",
        "\n",
        "            # Get categorical columns info\n",
        "            cat_cols = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "            num_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Task must be 'regression' or 'classification'\")\n",
        "\n",
        "        print(f\"\\nInitial shapes:\")\n",
        "        print(f\"  X_train: {X_train.shape}\")\n",
        "        print(f\"  X_test: {X_test.shape}\")\n",
        "\n",
        "        # Check for NaN before processing\n",
        "        print(f\"\\nChecking for NaN values before preprocessing:\")\n",
        "        print(f\"  X_train NaN count: {X_train.isna().sum().sum()}\")\n",
        "        print(f\"  X_test NaN count: {X_test.isna().sum().sum()}\")\n",
        "\n",
        "        # Step 1: Handle NaN values in categorical columns\n",
        "        print(\"\\n1. Handling NaN in categorical columns...\")\n",
        "        for col in cat_cols:\n",
        "            if col in X_train.columns:\n",
        "                # Fill NaN with mode for training, use training mode for test\n",
        "                mode_val = X_train[col].mode()[0] if not X_train[col].mode().empty else 'Unknown'\n",
        "                X_train[col] = X_train[col].fillna(mode_val)\n",
        "                X_test[col] = X_test[col].fillna(mode_val)\n",
        "                print(f\"  {col}: filled NaN with '{mode_val}'\")\n",
        "\n",
        "        # Step 2: Handle NaN values in numerical columns\n",
        "        print(\"2. Handling NaN in numerical columns...\")\n",
        "        for col in num_cols:\n",
        "            if col in X_train.columns:\n",
        "                # Fill NaN with median for training, use training median for test\n",
        "                median_val = X_train[col].median()\n",
        "                X_train[col] = X_train[col].fillna(median_val)\n",
        "                X_test[col] = X_test[col].fillna(median_val)\n",
        "                print(f\"  {col}: filled NaN with median {median_val:.4f}\")\n",
        "\n",
        "        # Step 3: Target encoding for categorical features\n",
        "        print(\"3. Applying target encoding...\")\n",
        "        if cat_cols:\n",
        "            # For regression\n",
        "            if task == 'regression':\n",
        "                try:\n",
        "                    from category_encoders import TargetEncoder\n",
        "                    encoder = TargetEncoder(cols=cat_cols)\n",
        "                    X_train_encoded = encoder.fit_transform(X_train, y_train)\n",
        "                    X_test_encoded = encoder.transform(X_test)\n",
        "\n",
        "                    # Store encoder for later use\n",
        "                    self.preprocessing_info[f'{task}_encoder'] = encoder\n",
        "                    print(f\"  Applied target encoding to {len(cat_cols)} categorical features\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"  Warning: Target encoding failed with error: {e}\")\n",
        "                    print(\"  Using label encoding instead...\")\n",
        "\n",
        "                    # Fallback to label encoding\n",
        "                    from sklearn.preprocessing import LabelEncoder\n",
        "                    X_train_encoded = X_train.copy()\n",
        "                    X_test_encoded = X_test.copy()\n",
        "\n",
        "                    for col in cat_cols:\n",
        "                        le = LabelEncoder()\n",
        "                        # Fit on train, transform both\n",
        "                        X_train_encoded[col] = le.fit_transform(X_train[col].astype(str))\n",
        "                        X_test_encoded[col] = le.transform(X_test[col].astype(str))\n",
        "\n",
        "                    print(f\"  Applied label encoding to {len(cat_cols)} categorical features\")\n",
        "\n",
        "            # For classification\n",
        "            else:\n",
        "                # For classification, using label encoding\n",
        "                from sklearn.preprocessing import LabelEncoder\n",
        "                X_train_encoded = X_train.copy()\n",
        "                X_test_encoded = X_test.copy()\n",
        "\n",
        "                for col in cat_cols:\n",
        "                    le = LabelEncoder()\n",
        "                    # Fit on train, transform both\n",
        "                    X_train_encoded[col] = le.fit_transform(X_train[col].astype(str))\n",
        "                    X_test_encoded[col] = le.transform(X_test[col].astype(str))\n",
        "\n",
        "                print(f\"  Applied label encoding to {len(cat_cols)} categorical features\")\n",
        "\n",
        "        else:\n",
        "            X_train_encoded = X_train.copy()\n",
        "            X_test_encoded = X_test.copy()\n",
        "            print(\"  No categorical columns to encode\")\n",
        "\n",
        "        # Step 4: Scaling numerical features\n",
        "        print(\"4. Scaling numerical features...\")\n",
        "        if num_cols:\n",
        "            scaler = StandardScaler()\n",
        "            X_train_encoded[num_cols] = scaler.fit_transform(X_train_encoded[num_cols])\n",
        "            X_test_encoded[num_cols] = scaler.transform(X_test_encoded[num_cols])\n",
        "\n",
        "            # Store scaler\n",
        "            self.preprocessing_info[f'{task}_scaler'] = scaler\n",
        "            print(f\"  Scaled {len(num_cols)} numerical features\")\n",
        "\n",
        "        # Check for NaN after scaling\n",
        "        print(f\"\\nChecking for NaN values after scaling:\")\n",
        "        print(f\"  X_train_encoded NaN count: {X_train_encoded.isna().sum().sum()}\")\n",
        "        print(f\"  X_test_encoded NaN count: {X_test_encoded.isna().sum().sum()}\")\n",
        "\n",
        "        # Handle any remaining NaN\n",
        "        if X_train_encoded.isna().sum().sum() > 0:\n",
        "            print(\"  Handling remaining NaN values...\")\n",
        "            X_train_encoded = X_train_encoded.fillna(0)\n",
        "            X_test_encoded = X_test_encoded.fillna(0)\n",
        "\n",
        "        # Step 5: Dimensionality reduction (PCA)\n",
        "        print(\"5. Applying PCA...\")\n",
        "        n_components = min(30, X_train_encoded.shape[1], X_train_encoded.shape[0] - 1)\n",
        "\n",
        "        if n_components > 1:\n",
        "            pca = PCA(n_components=n_components)\n",
        "\n",
        "            # Ensure no NaN values before PCA\n",
        "            if X_train_encoded.isna().any().any() or X_test_encoded.isna().any().any():\n",
        "                print(\"  Warning: NaN values detected before PCA - filling with 0\")\n",
        "                X_train_encoded = X_train_encoded.fillna(0)\n",
        "                X_test_encoded = X_test_encoded.fillna(0)\n",
        "\n",
        "            X_train_pca = pca.fit_transform(X_train_encoded)\n",
        "            X_test_pca = pca.transform(X_test_encoded)\n",
        "\n",
        "            # Store PCA info\n",
        "            self.preprocessing_info[f'{task}_pca'] = pca\n",
        "            self.preprocessing_info[f'{task}_explained_variance'] = pca.explained_variance_ratio_.sum()\n",
        "\n",
        "            print(f\"  Original features: {X_train_encoded.shape[1]}\")\n",
        "            print(f\"  PCA components: {n_components}\")\n",
        "            print(f\"  Explained variance: {pca.explained_variance_ratio_.sum():.3f}\")\n",
        "        else:\n",
        "            print(\"  Skipping PCA - insufficient components or samples\")\n",
        "            X_train_pca = X_train_encoded.values\n",
        "            X_test_pca = X_test_encoded.values\n",
        "\n",
        "        print(f\"\\nFinal shapes after preprocessing:\")\n",
        "        print(f\"  X_train_pca: {X_train_pca.shape}\")\n",
        "        print(f\"  X_test_pca: {X_test_pca.shape}\")\n",
        "\n",
        "        # Update the stored data\n",
        "        if task == 'regression':\n",
        "            self.X_train_reg = X_train_pca\n",
        "            self.X_test_reg = X_test_pca\n",
        "        else:\n",
        "            self.X_train_cls = X_train_pca\n",
        "            self.X_test_cls = X_test_pca\n",
        "\n",
        "        return X_train_pca, X_test_pca\n",
        "\n",
        "    def get_data_summary(self):\n",
        "        \"\"\"Get summary of prepared data\"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"DATA PREPARATION SUMMARY\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        summary = {}\n",
        "\n",
        "        if self.X_train_reg is not None:\n",
        "            print(\"\\nREGRESSION DATA:\")\n",
        "            print(\"-\" * 40)\n",
        "            print(f\"Training set: {self.X_train_reg.shape}\")\n",
        "            print(f\"Testing set: {self.X_test_reg.shape}\")\n",
        "            print(f\"Target range: [{self.y_train_reg.min():.2f}, {self.y_train_reg.max():.2f}]\")\n",
        "\n",
        "            summary['regression'] = {\n",
        "                'train_shape': self.X_train_reg.shape,\n",
        "                'test_shape': self.X_test_reg.shape,\n",
        "                'target_stats': {\n",
        "                    'min': self.y_train_reg.min(),\n",
        "                    'max': self.y_train_reg.max(),\n",
        "                    'mean': self.y_train_reg.mean(),\n",
        "                    'std': self.y_train_reg.std()\n",
        "                }\n",
        "            }\n",
        "\n",
        "        if self.X_train_cls is not None:\n",
        "            print(\"\\nCLASSIFICATION DATA:\")\n",
        "            print(\"-\" * 40)\n",
        "            print(f\"Training set: {self.X_train_cls.shape}\")\n",
        "            print(f\"Testing set: {self.X_test_cls.shape}\")\n",
        "            print(f\"Classes: {self.y_train_cls.unique()}\")\n",
        "            print(f\"Class distribution:\")\n",
        "            for class_val, count in self.y_train_cls.value_counts().items():\n",
        "                percentage = (count / len(self.y_train_cls)) * 100\n",
        "                print(f\"  Class {class_val}: {count} ({percentage:.1f}%)\")\n",
        "\n",
        "            summary['classification'] = {\n",
        "                'train_shape': self.X_train_cls.shape,\n",
        "                'test_shape': self.X_test_cls.shape,\n",
        "                'class_distribution': self.y_train_cls.value_counts().to_dict()\n",
        "            }\n",
        "\n",
        "        return summary\n",
        "\n",
        "# ============================================================================\n",
        "# RUN THE FIXED DATA PREPARATION\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"STARTING DATA PREPARATION (FIXED VERSION)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Create new preparer with the fixed class\n",
        "preparer = DataPreparer(df)\n",
        "\n",
        "# Prepare regression data\n",
        "X_train_reg, X_test_reg, y_train_reg, y_test_reg = preparer.prepare_regression_data(\n",
        "    target_col='selling_price', test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Prepare classification data (initial split only)\n",
        "# This sets preparer.X_train_cls, preparer.X_test_cls, preparer.y_train_cls, preparer.y_test_cls with initial split data\n",
        "preparer.prepare_classification_data(\n",
        "    target_col='leads', test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Apply preprocessing pipelines for REGRESSION\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"APPLYING PREPROCESSING PIPELINES (WITH PROPER NaN HANDLING)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "try:\n",
        "    X_train_reg_pca, X_test_reg_pca = preparer.apply_preprocessing_pipeline(task='regression')\n",
        "    print(\"\\n✅ Regression preprocessing completed successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n❌ Error in regression preprocessing: {e}\")\n",
        "    print(\"Trying alternative approach...\")\n",
        "\n",
        "    # Alternative: Skip PCA if it fails\n",
        "    print(\"Skipping PCA and using scaled features directly...\")\n",
        "    X_train_reg_pca = preparer.X_train_reg\n",
        "    X_test_reg_pca = preparer.X_test_reg\n",
        "\n",
        "# Classification preprocessing: Run this first to clean and transform the data\n",
        "# This will update preparer.X_train_cls and preparer.X_test_cls to be numerical and NaN-free (PCA-transformed)\n",
        "try:\n",
        "    # We assign the output to X_train_cls_pca and X_test_cls_pca to keep track,\n",
        "    # and also rely on preparer's internal X_train_cls and X_test_cls being updated.\n",
        "    X_train_cls_pca, X_test_cls_pca = preparer.apply_preprocessing_pipeline(task='classification')\n",
        "    print(\"\\n✅ Classification preprocessing completed successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n❌ Error in classification preprocessing: {e}\")\n",
        "    print(\"Trying alternative approach...\")\n",
        "    print(\"Skipping PCA and using scaled features directly...\")\n",
        "    X_train_cls_pca = preparer.X_train_cls\n",
        "    X_test_cls_pca = preparer.X_test_cls\n",
        "\n",
        "\n",
        "# Now handle class imbalance for classification.\n",
        "# This will operate on the already preprocessed (NaN-handled, encoded, scaled, PCA'd) X_train_cls\n",
        "# stored in preparer. The method will internally use self.X_train_cls and self.y_train_cls,\n",
        "# and update them to the SMOTEd versions.\n",
        "# The returned values X_train_cls_res and y_train_cls_res will be these updated versions.\n",
        "X_train_cls_res, y_train_cls_res = preparer.handle_class_imbalance(method='smote')\n",
        "\n",
        "# Get final data summary\n",
        "data_summary = preparer.get_data_summary()\n",
        "\n",
        "# ============================================================================\n",
        "# ADDITIONAL DATA QUALITY CHECKS\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"DATA QUALITY CHECKS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Check for NaN in final datasets\n",
        "print(\"\\nChecking for NaN in final datasets:\")\n",
        "print(f\"Regression - X_train NaN: {np.isnan(X_train_reg_pca).sum()}\")\n",
        "print(f\"Regression - X_test NaN: {np.isnan(X_test_reg_pca).sum()}\")\n",
        "print(f\"Regression - y_train NaN: {np.isnan(y_train_reg).sum()}\")\n",
        "print(f\"Regression - y_test NaN: {np.isnan(y_test_reg).sum()}\")\n",
        "\n",
        "print(f\"\\nClassification - X_train NaN: {np.isnan(X_train_cls_res).sum()}\") # Use the SMOTEd final train\n",
        "print(f\"Classification - X_test NaN: {np.isnan(X_test_cls_pca).sum()}\")   # Use the non-SMOTEd final test\n",
        "print(f\"Classification - y_train NaN: {np.isnan(y_train_cls_res).sum()}\") # Use the SMOTEd final train target\n",
        "print(f\"Classification - y_test NaN: {np.isnan(y_test_cls).sum()}\") # Use the original test target\n",
        "\n",
        "# Check data types\n",
        "print(\"\\nChecking data types:\")\n",
        "print(f\"Regression X type: {type(X_train_reg_pca)}\")\n",
        "print(f\"Regression y type: {type(y_train_reg)}\")\n",
        "print(f\"Classification X type: {type(X_train_cls_res)}\") # Use final\n",
        "print(f\"Classification y type: {type(y_train_cls_res)}\") # Use final\n",
        "\n",
        "# Ensure arrays are numpy arrays for modeling later\n",
        "if isinstance(X_train_reg_pca, pd.DataFrame):\n",
        "    X_train_reg_pca = X_train_reg_pca.values\n",
        "    X_test_reg_pca = X_test_reg_pca.values\n",
        "\n",
        "# X_train_cls_res is already an np.array from SMOTE. X_test_cls_pca might be DataFrame or array.\n",
        "if isinstance(X_train_cls_res, pd.DataFrame):\n",
        "    X_train_cls_res = X_train_cls_res.values\n",
        "\n",
        "if isinstance(X_test_cls_pca, pd.DataFrame):\n",
        "    X_test_cls_pca = X_test_cls_pca.values\n",
        "\n",
        "if isinstance(y_train_reg, pd.Series):\n",
        "    y_train_reg = y_train_reg.values\n",
        "    y_test_reg = y_test_reg.values\n",
        "\n",
        "if isinstance(y_train_cls_res, pd.Series):\n",
        "    y_train_cls_res = y_train_cls_res.values\n",
        "\n",
        "# y_test_cls was already a Series from prepare_classification_data, ensure it's numpy array if needed for models\n",
        "if isinstance(y_test_cls, pd.Series):\n",
        "    y_test_cls = y_test_cls.values\n",
        "\n",
        "print(\"\\n✅ Data preparation completed successfully!\")\n",
        "print(\"Ready for modeling...\")"
      ],
      "metadata": {
        "id": "BYYugn-_e730"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Regression: Selling Price Prediction <a name=\"regression\"></a>"
      ],
      "metadata": {
        "id": "NXHzJfpqZ1MW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# SECTION 6: REGRESSION MODELING - SELLING PRICE PREDICTION\n",
        "# ============================================================================\n",
        "\n",
        "class RegressionModeler:\n",
        "    \"\"\"Handles regression modeling for selling price prediction\"\"\"\n",
        "\n",
        "    def __init__(self, X_train, X_test, y_train, y_test):\n",
        "        self.X_train = X_train\n",
        "        self.X_test = X_test\n",
        "        self.y_train = y_train\n",
        "        self.y_test = y_test\n",
        "        self.models = {}\n",
        "        self.results = {}\n",
        "        self.best_model = None\n",
        "\n",
        "    def train_baseline_models(self):\n",
        "        \"\"\"Train multiple baseline regression models\"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"TRAINING BASELINE REGRESSION MODELS\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        # Define models to train\n",
        "        baseline_models = {\n",
        "            'Linear Regression': LinearRegression(),\n",
        "            'Ridge Regression': Ridge(alpha=1.0),\n",
        "            'Lasso Regression': Lasso(alpha=1.0),\n",
        "            'Decision Tree': DecisionTreeRegressor(random_state=42, max_depth=10),\n",
        "            'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1),\n",
        "            'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
        "            'XGBoost': XGBRegressor(n_estimators=100, random_state=42, verbosity=0),\n",
        "            'LightGBM': LGBMRegressor(n_estimators=100, random_state=42, verbose=-1)\n",
        "        }\n",
        "\n",
        "        # Train and evaluate each model\n",
        "        for name, model in baseline_models.items():\n",
        "            print(f\"\\nTraining {name}...\")\n",
        "\n",
        "            # Train model\n",
        "            model.fit(self.X_train, self.y_train)\n",
        "            self.models[name] = model\n",
        "\n",
        "            # Make predictions\n",
        "            y_pred_train = model.predict(self.X_train)\n",
        "            y_pred_test = model.predict(self.X_test)\n",
        "\n",
        "            # Calculate metrics\n",
        "            train_mse = mean_squared_error(self.y_train, y_pred_train)\n",
        "            test_mse = mean_squared_error(self.y_test, y_pred_test)\n",
        "            train_rmse = np.sqrt(train_mse)\n",
        "            test_rmse = np.sqrt(test_mse)\n",
        "            train_mae = mean_absolute_error(self.y_train, y_pred_train)\n",
        "            test_mae = mean_absolute_error(self.y_test, y_pred_test)\n",
        "            train_r2 = r2_score(self.y_train, y_pred_train)\n",
        "            test_r2 = r2_score(self.y_test, y_pred_test)\n",
        "\n",
        "            # Store results\n",
        "            self.results[name] = {\n",
        "                'train_mse': train_mse,\n",
        "                'test_mse': test_mse,\n",
        "                'train_rmse': train_rmse,\n",
        "                'test_rmse': test_rmse,\n",
        "                'train_mae': train_mae,\n",
        "                'test_mae': test_mae,\n",
        "                'train_r2': train_r2,\n",
        "                'test_r2': test_r2,\n",
        "                'overfit_score': train_r2 - test_r2  # Positive = overfitting\n",
        "            }\n",
        "\n",
        "            # Print results\n",
        "            print(f\"  R² Score: {test_r2:.4f}\")\n",
        "            print(f\"  RMSE: {test_rmse:.4f}\")\n",
        "            print(f\"  MAE: {test_mae:.4f}\")\n",
        "\n",
        "        return self.results\n",
        "\n",
        "    def compare_models(self):\n",
        "        \"\"\"Compare performance of all trained models\"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"MODEL COMPARISON\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        # Convert results to DataFrame\n",
        "        results_df = pd.DataFrame(self.results).T\n",
        "\n",
        "        # Sort by test R² score\n",
        "        results_df = results_df.sort_values('test_r2', ascending=False)\n",
        "\n",
        "        print(\"\\nModel Performance Ranking (by Test R² Score):\")\n",
        "        print(\"-\" * 100)\n",
        "        print(results_df[['test_r2', 'test_rmse', 'test_mae', 'overfit_score']].round(4))\n",
        "\n",
        "        # Visual comparison\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "        # R² Comparison\n",
        "        axes[0, 0].barh(range(len(results_df)), results_df['test_r2'].values, color='skyblue')\n",
        "        axes[0, 0].set_yticks(range(len(results_df)))\n",
        "        axes[0, 0].set_yticklabels(results_df.index)\n",
        "        axes[0, 0].set_xlabel('R² Score')\n",
        "        axes[0, 0].set_title('Model Comparison - R² Score')\n",
        "        axes[0, 0].invert_yaxis()\n",
        "\n",
        "        # RMSE Comparison\n",
        "        axes[0, 1].barh(range(len(results_df)), results_df['test_rmse'].values, color='lightcoral')\n",
        "        axes[0, 1].set_yticks(range(len(results_df)))\n",
        "        axes[0, 1].set_yticklabels(results_df.index)\n",
        "        axes[0, 1].set_xlabel('RMSE')\n",
        "        axes[0, 1].set_title('Model Comparison - RMSE')\n",
        "        axes[0, 1].invert_yaxis()\n",
        "\n",
        "        # Overfitting Analysis\n",
        "        axes[1, 0].barh(range(len(results_df)), results_df['overfit_score'].values, color='lightgreen')\n",
        "        axes[1, 0].set_yticks(range(len(results_df)))\n",
        "        axes[1, 0].set_yticklabels(results_df.index)\n",
        "        axes[1, 0].set_xlabel('Train R² - Test R²')\n",
        "        axes[1, 0].set_title('Overfitting Analysis')\n",
        "        axes[1, 0].axvline(x=0, color='red', linestyle='--', alpha=0.5)\n",
        "        axes[1, 0].invert_yaxis()\n",
        "\n",
        "        # Prediction vs Actual for best model\n",
        "        best_model_name = results_df.index[0]\n",
        "        best_model = self.models[best_model_name]\n",
        "        y_pred_best = best_model.predict(self.X_test)\n",
        "\n",
        "        axes[1, 1].scatter(self.y_test, y_pred_best, alpha=0.5, color='purple')\n",
        "        axes[1, 1].plot([self.y_test.min(), self.y_test.max()],\n",
        "                       [self.y_test.min(), self.y_test.max()],\n",
        "                       'r--', lw=2)\n",
        "        axes[1, 1].set_xlabel('Actual Values')\n",
        "        axes[1, 1].set_ylabel('Predicted Values')\n",
        "        axes[1, 1].set_title(f'Actual vs Predicted - {best_model_name}')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Identify best model\n",
        "        self.best_model = {\n",
        "            'name': best_model_name,\n",
        "            'model': best_model,\n",
        "            'metrics': results_df.loc[best_model_name].to_dict()\n",
        "        }\n",
        "\n",
        "        print(f\"\\n🎯 BEST MODEL: {best_model_name}\")\n",
        "        print(f\"   Test R²: {self.best_model['metrics']['test_r2']:.4f}\")\n",
        "        print(f\"   Test RMSE: {self.best_model['metrics']['test_rmse']:.4f}\")\n",
        "        print(f\"   Test MAE: {self.best_model['metrics']['test_mae']:.4f}\")\n",
        "\n",
        "        return results_df\n",
        "\n",
        "    def hyperparameter_tuning(self, model_name='Random Forest', n_iter=50):\n",
        "        \"\"\"Perform hyperparameter tuning for a specific model\"\"\"\n",
        "        print(f\"\\n\" + \"=\"*80)\n",
        "        print(f\"HYPERPARAMETER TUNING: {model_name}\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        if model_name not in self.models:\n",
        "            print(f\"Model {model_name} not found in trained models!\")\n",
        "            return None\n",
        "\n",
        "        # Define parameter grids for different models\n",
        "        param_grids = {\n",
        "            'Random Forest': {\n",
        "                # 'n_estimators': [100, 200, 300, 500],\n",
        "                # 'max_depth': [10, 20, 30, None],\n",
        "                # 'min_samples_split': [2, 5, 10],\n",
        "                # 'min_samples_leaf': [1, 2, 4],\n",
        "                # 'max_features': ['sqrt', 'log2']\n",
        "\n",
        "                'n_estimators': [75, 100, 125],          # Small variations\n",
        "                'max_depth': [None, 25, 30],             # Try limiting depth\n",
        "                'min_samples_split': [2, 3, 4],          # Small adjustments\n",
        "                'min_samples_leaf': [1, 2],              # Minimal change\n",
        "                'max_features': ['sqrt', 0.8, 'log2']    # Different options\n",
        "\n",
        "\n",
        "            },\n",
        "            'Gradient Boosting': {\n",
        "                'n_estimators': [100, 200, 300],\n",
        "                'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
        "                'max_depth': [3, 5, 7, 9],\n",
        "                'subsample': [0.8, 0.9, 1.0],\n",
        "                'min_samples_split': [2, 5, 10]\n",
        "            },\n",
        "            'XGBoost': {\n",
        "                'n_estimators': [100, 200, 300],\n",
        "                'max_depth': [3, 5, 7, 9],\n",
        "                'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
        "                'subsample': [0.8, 0.9, 1.0],\n",
        "                'colsample_bytree': [0.8, 0.9, 1.0]\n",
        "            },\n",
        "            'LightGBM': {\n",
        "                'n_estimators': [100, 200, 300],\n",
        "                'num_leaves': [31, 50, 100],\n",
        "                'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
        "                'subsample': [0.8, 0.9, 1.0],\n",
        "                'colsample_bytree': [0.8, 0.9, 1.0]\n",
        "            }\n",
        "        }\n",
        "\n",
        "        if model_name not in param_grids:\n",
        "            print(f\"No parameter grid defined for {model_name}\")\n",
        "            return None\n",
        "\n",
        "        # Get base model\n",
        "        base_model = self.models[model_name]\n",
        "\n",
        "        # Perform Randomized Search\n",
        "        print(f\"Performing RandomizedSearchCV with {n_iter} iterations...\")\n",
        "        random_search = RandomizedSearchCV(\n",
        "            estimator=base_model,\n",
        "            param_distributions=param_grids[model_name],\n",
        "            n_iter=n_iter,\n",
        "            cv=3,\n",
        "            scoring='neg_mean_squared_error',\n",
        "            random_state=42,\n",
        "            n_jobs=-1,\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        # Fit the random search\n",
        "        random_search.fit(self.X_train, self.y_train)\n",
        "\n",
        "        # Get best parameters and score\n",
        "        best_params = random_search.best_params_\n",
        "        best_score = -random_search.best_score_  # Convert back from negative MSE\n",
        "\n",
        "        print(f\"\\n✅ Tuning completed!\")\n",
        "        print(f\"Best Parameters: {best_params}\")\n",
        "        print(f\"Best MSE: {best_score:.4f}\")\n",
        "        print(f\"Best RMSE: {np.sqrt(best_score):.4f}\")\n",
        "\n",
        "        # Update model with best parameters\n",
        "        tuned_model = random_search.best_estimator_\n",
        "        self.models[f\"{model_name} (Tuned)\"] = tuned_model\n",
        "\n",
        "        # Evaluate tuned model\n",
        "        y_pred_tuned = tuned_model.predict(self.X_test)\n",
        "        tuned_r2 = r2_score(self.y_test, y_pred_tuned)\n",
        "        tuned_rmse = np.sqrt(mean_squared_error(self.y_test, y_pred_tuned))\n",
        "\n",
        "        print(f\"\\nTuned Model Performance:\")\n",
        "        print(f\"  Test R²: {tuned_r2:.4f}\")\n",
        "        print(f\"  Test RMSE: {tuned_rmse:.4f}\")\n",
        "\n",
        "        # Compare with baseline\n",
        "        baseline_r2 = self.results[model_name]['test_r2']\n",
        "        improvement = tuned_r2 - baseline_r2\n",
        "\n",
        "        print(f\"\\nImprovement over baseline: {improvement:.4f}\")\n",
        "        if improvement > 0:\n",
        "            print(\"✅ Tuning improved performance!\")\n",
        "        else:\n",
        "            print(\"⚠️  Tuning did not improve performance\")\n",
        "\n",
        "        return {\n",
        "            'best_params': best_params,\n",
        "            'best_score': best_score,\n",
        "            'tuned_model': tuned_model,\n",
        "            'test_r2': tuned_r2,\n",
        "            'test_rmse': tuned_rmse,\n",
        "            'improvement': improvement\n",
        "        }\n",
        "\n",
        "    def feature_importance_analysis(self, model_name=None):\n",
        "        \"\"\"Analyze feature importance for tree-based models\"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"FEATURE IMPORTANCE ANALYSIS\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        if model_name is None:\n",
        "            # Use best model if available, otherwise use Random Forest\n",
        "            if self.best_model:\n",
        "                model_name = self.best_model['name']\n",
        "            else:\n",
        "                model_name = 'Random Forest'\n",
        "\n",
        "        if model_name not in self.models:\n",
        "            print(f\"Model {model_name} not found!\")\n",
        "            return None\n",
        "\n",
        "        model = self.models[model_name]\n",
        "\n",
        "        # Check if model has feature_importances_ attribute\n",
        "        if hasattr(model, 'feature_importances_'):\n",
        "            importances = model.feature_importances_\n",
        "\n",
        "            # Create DataFrame\n",
        "            feature_names = [f'Feature_{i}' for i in range(len(importances))]\n",
        "            importance_df = pd.DataFrame({\n",
        "                'feature': feature_names,\n",
        "                'importance': importances\n",
        "            }).sort_values('importance', ascending=False)\n",
        "\n",
        "            # Plot top 20 features\n",
        "            top_n = min(20, len(importance_df))\n",
        "            plt.figure(figsize=(10, 8))\n",
        "            plt.barh(range(top_n), importance_df['importance'].head(top_n), color='steelblue')\n",
        "            plt.yticks(range(top_n), importance_df['feature'].head(top_n))\n",
        "            plt.xlabel('Feature Importance')\n",
        "            plt.title(f'Top {top_n} Feature Importances - {model_name}')\n",
        "            plt.gca().invert_yaxis()\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "            print(f\"\\nTop 10 Most Important Features:\")\n",
        "            print(\"-\" * 50)\n",
        "            for i, (_, row) in enumerate(importance_df.head(10).iterrows(), 1):\n",
        "                print(f\"{i:2}. {row['feature']:20} : {row['importance']:.4f}\")\n",
        "\n",
        "            return importance_df\n",
        "        else:\n",
        "            print(f\"Model {model_name} does not support feature importance analysis\")\n",
        "            return None\n",
        "\n",
        "    def save_model(self, model_name, filepath):\n",
        "        \"\"\"Save trained model to file\"\"\"\n",
        "        if model_name in self.models:\n",
        "            joblib.dump(self.models[model_name], filepath)\n",
        "            print(f\"✅ Model saved to: {filepath}\")\n",
        "            return True\n",
        "        else:\n",
        "            print(f\"Model {model_name} not found!\")\n",
        "            return False\n",
        "\n",
        "    def generate_regression_report(self):\n",
        "        \"\"\"Generate comprehensive regression report\"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"REGRESSION MODELING REPORT\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        # Train baseline models\n",
        "        self.train_baseline_models()\n",
        "\n",
        "        # Compare models\n",
        "        comparison_df = self.compare_models()\n",
        "\n",
        "        # Hyperparameter tuning for best model\n",
        "        if self.best_model:\n",
        "            tuning_results = self.hyperparameter_tuning(\n",
        "                model_name=self.best_model['name'],\n",
        "                n_iter=30\n",
        "            )\n",
        "\n",
        "        # Feature importance analysis\n",
        "        importance_df = self.feature_importance_analysis()\n",
        "\n",
        "        # Final recommendations\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"FINAL RECOMMENDATIONS\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        if self.best_model:\n",
        "            print(f\"\\n🎯 Recommended Model: {self.best_model['name']}\")\n",
        "            print(f\"   Performance: R² = {self.best_model['metrics']['test_r2']:.4f}\")\n",
        "            print(f\"   Error: RMSE = {self.best_model['metrics']['test_rmse']:.4f}\")\n",
        "\n",
        "            # Check for overfitting\n",
        "            if self.best_model['metrics']['overfit_score'] > 0.1:\n",
        "                print(f\"   ⚠️  Warning: Potential overfitting detected\")\n",
        "                print(f\"      (Train R² - Test R² = {self.best_model['metrics']['overfit_score']:.4f})\")\n",
        "\n",
        "        print(\"\\nNext Steps:\")\n",
        "        print(\"1. Consider ensemble methods (Stacking, Voting)\")\n",
        "        print(\"2. Further feature engineering based on importance analysis\")\n",
        "        print(\"3. Collect more data if possible\")\n",
        "        print(\"4. Validate on completely unseen dataset\")\n",
        "\n",
        "        return {\n",
        "            'comparison': comparison_df,\n",
        "            'best_model': self.best_model,\n",
        "            'feature_importance': importance_df\n",
        "        }\n",
        "\n",
        "# Initialize and run regression modeling\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"STARTING REGRESSION MODELING\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "reg_modeler = RegressionModeler(\n",
        "    X_train_reg_pca, X_test_reg_pca,\n",
        "    y_train_reg, y_test_reg\n",
        ")\n",
        "\n",
        "regression_report = reg_modeler.generate_regression_report()\n",
        "\n",
        "# Save the best regression model\n",
        "if reg_modeler.best_model:\n",
        "    reg_modeler.save_model(\n",
        "        reg_modeler.best_model['name'],\n",
        "        'best_regression_model.pkl'\n",
        "    )"
      ],
      "metadata": {
        "id": "xijUP13RaFDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 8. Classification: Lead Outcome Prediction <a name=\"classification\"></a>\n"
      ],
      "metadata": {
        "id": "dr6Zl3bAgBPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================================================\n",
        "# SECTION 7: CLASSIFICATION MODELING - LEAD OUTCOME PREDICTION\n",
        "# ============================================================================\n",
        "\n",
        "class ClassificationModeler:\n",
        "    \"\"\"Handles classification modeling for lead outcome prediction\"\"\"\n",
        "\n",
        "    def __init__(self, X_train, X_test, y_train, y_test):\n",
        "        self.X_train = X_train\n",
        "        self.X_test = X_test\n",
        "        self.y_train = y_train\n",
        "        self.y_test = y_test\n",
        "        self.models = {}\n",
        "        self.results = {}\n",
        "        self.best_model = None\n",
        "\n",
        "    def train_baseline_models(self):\n",
        "        \"\"\"Train multiple baseline classification models\"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"TRAINING BASELINE CLASSIFICATION MODELS\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        # Define models to train\n",
        "        baseline_models = {\n",
        "            'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
        "            'Decision Tree': DecisionTreeClassifier(random_state=42, max_depth=10),\n",
        "            'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
        "            'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
        "            'XGBoost': XGBClassifier(n_estimators=100, random_state=42, verbosity=0),\n",
        "            'LightGBM': LGBMClassifier(n_estimators=100, random_state=42, verbose=-1),\n",
        "            'SVM': SVC(random_state=42, probability=True)\n",
        "        }\n",
        "\n",
        "        # Train and evaluate each model\n",
        "        for name, model in baseline_models.items():\n",
        "            print(f\"\\nTraining {name}...\")\n",
        "\n",
        "            try:\n",
        "                # Train model\n",
        "                model.fit(self.X_train, self.y_train)\n",
        "                self.models[name] = model\n",
        "\n",
        "                # Make predictions\n",
        "                y_pred_train = model.predict(self.X_train)\n",
        "                y_pred_test = model.predict(self.X_test)\n",
        "                y_pred_proba = model.predict_proba(self.X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
        "\n",
        "                # Calculate metrics\n",
        "                train_accuracy = accuracy_score(self.y_train, y_pred_train)\n",
        "                test_accuracy = accuracy_score(self.y_test, y_pred_test)\n",
        "                train_precision = precision_score(self.y_train, y_pred_train, average='weighted')\n",
        "                test_precision = precision_score(self.y_test, y_pred_test, average='weighted')\n",
        "                train_recall = recall_score(self.y_train, y_pred_train, average='weighted')\n",
        "                test_recall = recall_score(self.y_test, y_pred_test, average='weighted')\n",
        "                train_f1 = f1_score(self.y_train, y_pred_train, average='weighted')\n",
        "                test_f1 = f1_score(self.y_test, y_pred_test, average='weighted')\n",
        "\n",
        "                # ROC-AUC if probabilities available\n",
        "                roc_auc = roc_auc_score(self.y_test, y_pred_proba) if y_pred_proba is not None else None\n",
        "\n",
        "                # Store results\n",
        "                self.results[name] = {\n",
        "                    'train_accuracy': train_accuracy,\n",
        "                    'test_accuracy': test_accuracy,\n",
        "                    'train_precision': train_precision,\n",
        "                    'test_precision': test_precision,\n",
        "                    'train_recall': train_recall,\n",
        "                    'test_recall': test_recall,\n",
        "                    'train_f1': train_f1,\n",
        "                    'test_f1': test_f1,\n",
        "                    'roc_auc': roc_auc,\n",
        "                    'overfit_score': train_accuracy - test_accuracy\n",
        "                }\n",
        "\n",
        "                # Print results\n",
        "                print(f\"  Accuracy: {test_accuracy:.4f}\")\n",
        "                print(f\"  F1-Score: {test_f1:.4f}\")\n",
        "                print(f\"  Precision: {test_precision:.4f}\")\n",
        "                print(f\"  Recall: {test_recall:.4f}\")\n",
        "                if roc_auc is not None:\n",
        "                    print(f\"  ROC-AUC: {roc_auc:.4f}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"  Error training {name}: {e}\")\n",
        "                continue\n",
        "\n",
        "        return self.results\n",
        "\n",
        "    def compare_models(self):\n",
        "        \"\"\"Compare performance of all trained models\"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"MODEL COMPARISON\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        # Convert results to DataFrame\n",
        "        results_df = pd.DataFrame(self.results).T\n",
        "\n",
        "        # Sort by test F1 score (or accuracy if F1 not available)\n",
        "        sort_column = 'test_f1' if 'test_f1' in results_df.columns else 'test_accuracy'\n",
        "        results_df = results_df.sort_values(sort_column, ascending=False)\n",
        "\n",
        "        print(\"\\nModel Performance Ranking:\")\n",
        "        print(\"-\" * 100)\n",
        "        display_cols = ['test_accuracy', 'test_f1', 'test_precision', 'test_recall', 'roc_auc', 'overfit_score']\n",
        "        display_cols = [col for col in display_cols if col in results_df.columns]\n",
        "        print(results_df[display_cols].round(4))\n",
        "\n",
        "        # Visual comparison\n",
        "        fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "        axes = axes.flatten()\n",
        "\n",
        "        metrics_to_plot = ['test_accuracy', 'test_f1', 'test_precision', 'test_recall', 'roc_auc', 'overfit_score']\n",
        "\n",
        "        for idx, metric in enumerate(metrics_to_plot):\n",
        "            if idx >= len(axes) or metric not in results_df.columns:\n",
        "                fig.delaxes(axes[idx])\n",
        "                continue\n",
        "\n",
        "            ax = axes[idx]\n",
        "            values = results_df[metric].values\n",
        "            colors = ['skyblue' if v >= 0 else 'lightcoral' for v in values] if metric == 'overfit_score' else 'lightgreen'\n",
        "\n",
        "            ax.barh(range(len(results_df)), values, color=colors)\n",
        "            ax.set_yticks(range(len(results_df)))\n",
        "            ax.set_yticklabels(results_df.index)\n",
        "            ax.set_xlabel(metric.replace('_', ' ').title())\n",
        "            ax.set_title(f'Model Comparison - {metric.replace(\"_\", \" \").title()}')\n",
        "            ax.invert_yaxis()\n",
        "\n",
        "            if metric == 'overfit_score':\n",
        "                ax.axvline(x=0, color='red', linestyle='--', alpha=0.5)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Identify best model (based on F1 score)\n",
        "        if 'test_f1' in results_df.columns:\n",
        "            best_model_name = results_df['test_f1'].idxmax()\n",
        "        else:\n",
        "            best_model_name = results_df['test_accuracy'].idxmax()\n",
        "\n",
        "        self.best_model = {\n",
        "            'name': best_model_name,\n",
        "            'model': self.models[best_model_name],\n",
        "            'metrics': results_df.loc[best_model_name].to_dict()\n",
        "        }\n",
        "\n",
        "        print(f\"\\n🎯 BEST MODEL: {best_model_name}\")\n",
        "        print(f\"   Accuracy: {self.best_model['metrics']['test_accuracy']:.4f}\")\n",
        "        print(f\"   F1-Score: {self.best_model['metrics'].get('test_f1', 'N/A')}\")\n",
        "        print(f\"   Precision: {self.best_model['metrics'].get('test_precision', 'N/A')}\")\n",
        "        print(f\"   Recall: {self.best_model['metrics'].get('test_recall', 'N/A')}\")\n",
        "\n",
        "        return results_df\n",
        "\n",
        "    def plot_confusion_matrix(self, model_name=None):\n",
        "        \"\"\"Plot confusion matrix for a specific model\"\"\"\n",
        "        if model_name is None:\n",
        "            if self.best_model:\n",
        "                model_name = self.best_model['name']\n",
        "            else:\n",
        "                print(\"No model specified and no best model found!\")\n",
        "                return\n",
        "\n",
        "        if model_name not in self.models:\n",
        "            print(f\"Model {model_name} not found!\")\n",
        "            return\n",
        "\n",
        "        model = self.models[model_name]\n",
        "        y_pred = model.predict(self.X_test)\n",
        "\n",
        "        # Calculate confusion matrix\n",
        "        cm = confusion_matrix(self.y_test, y_pred)\n",
        "\n",
        "        # Plot\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                   xticklabels=['Lost', 'Won'], yticklabels=['Lost', 'Won'])\n",
        "        plt.title(f'Confusion Matrix - {model_name}')\n",
        "        plt.ylabel('Actual')\n",
        "        plt.xlabel('Predicted')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Print classification report\n",
        "        print(f\"\\nClassification Report - {model_name}:\")\n",
        "        print(\"-\" * 60)\n",
        "        print(classification_report(self.y_test, y_pred,\n",
        "                                   target_names=['Lost', 'Won']))\n",
        "\n",
        "        return cm\n",
        "\n",
        "    def plot_roc_curves(self):\n",
        "        \"\"\"Plot ROC curves for all models that support probability predictions\"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"ROC CURVES COMPARISON\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        plt.figure(figsize=(10, 8))\n",
        "\n",
        "        for name, model in self.models.items():\n",
        "            if hasattr(model, 'predict_proba'):\n",
        "                try:\n",
        "                    y_pred_proba = model.predict_proba(self.X_test)[:, 1]\n",
        "                    fpr, tpr, _ = roc_curve(self.y_test, y_pred_proba)\n",
        "                    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "                    plt.plot(fpr, tpr, lw=2, label=f'{name} (AUC = {roc_auc:.3f})')\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "        plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Random Guess')\n",
        "        plt.xlim([0.0, 1.0])\n",
        "        plt.ylim([0.0, 1.05])\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title('Receiver Operating Characteristic (ROC) Curves')\n",
        "        plt.legend(loc=\"lower right\")\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def hyperparameter_tuning(self, model_name='Random Forest', n_iter=50):\n",
        "        \"\"\"Perform hyperparameter tuning for a specific model\"\"\"\n",
        "        print(f\"\\n\" + \"=\"*80)\n",
        "        print(f\"HYPERPARAMETER TUNING: {model_name}\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        if model_name not in self.models:\n",
        "            print(f\"Model {model_name} not found in trained models!\")\n",
        "            return None\n",
        "\n",
        "        # Define parameter grids for different models\n",
        "        param_grids = {\n",
        "            'Random Forest': {\n",
        "                'n_estimators': [100, 200, 300, 500],\n",
        "                'max_depth': [10, 20, 30, None],\n",
        "                'min_samples_split': [2, 5, 10],\n",
        "                'min_samples_leaf': [1, 2, 4],\n",
        "                'max_features': ['sqrt', 'log2'],\n",
        "                'class_weight': [None, 'balanced']\n",
        "            },\n",
        "            'Gradient Boosting': {\n",
        "                'n_estimators': [100, 200, 300],\n",
        "                'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
        "                'max_depth': [3, 5, 7, 9],\n",
        "                'subsample': [0.8, 0.9, 1.0],\n",
        "                'min_samples_split': [2, 5, 10]\n",
        "            },\n",
        "            'XGBoost': {\n",
        "                'n_estimators': [100, 200, 300],\n",
        "                'max_depth': [3, 5, 7, 9],\n",
        "                'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
        "                'subsample': [0.8, 0.9, 1.0],\n",
        "                'colsample_bytree': [0.8, 0.9, 1.0],\n",
        "                'scale_pos_weight': [1, 2, 5, 10]  # For handling class imbalance\n",
        "            },\n",
        "            'Logistic Regression': {\n",
        "                'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "                'penalty': ['l1', 'l2', 'elasticnet'],\n",
        "                'solver': ['newton-cg', 'lbfgs', 'liblinear', 'saga'],\n",
        "                'class_weight': [None, 'balanced']\n",
        "            }\n",
        "        }\n",
        "\n",
        "        if model_name not in param_grids:\n",
        "            print(f\"No parameter grid defined for {model_name}\")\n",
        "            return None\n",
        "\n",
        "        # Get base model\n",
        "        base_model = self.models[model_name]\n",
        "\n",
        "        # Perform Randomized Search\n",
        "        print(f\"Performing RandomizedSearchCV with {n_iter} iterations...\")\n",
        "        random_search = RandomizedSearchCV(\n",
        "            estimator=base_model,\n",
        "            param_distributions=param_grids[model_name],\n",
        "            n_iter=n_iter,\n",
        "            cv=3,\n",
        "            scoring='f1_weighted',\n",
        "            random_state=42,\n",
        "            n_jobs=-1,\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        # Fit the random search\n",
        "        random_search.fit(self.X_train, self.y_train)\n",
        "\n",
        "        # Get best parameters and score\n",
        "        best_params = random_search.best_params_\n",
        "        best_score = random_search.best_score_\n",
        "\n",
        "        print(f\"\\n✅ Tuning completed!\")\n",
        "        print(f\"Best Parameters: {best_params}\")\n",
        "        print(f\"Best F1 Score: {best_score:.4f}\")\n",
        "\n",
        "        # Update model with best parameters\n",
        "        tuned_model = random_search.best_estimator_\n",
        "        self.models[f\"{model_name} (Tuned)\"] = tuned_model\n",
        "\n",
        "        # Evaluate tuned model\n",
        "        y_pred_tuned = tuned_model.predict(self.X_test)\n",
        "        tuned_accuracy = accuracy_score(self.y_test, y_pred_tuned)\n",
        "        tuned_f1 = f1_score(self.y_test, y_pred_tuned, average='weighted')\n",
        "\n",
        "        print(f\"\\nTuned Model Performance:\")\n",
        "        print(f\"  Test Accuracy: {tuned_accuracy:.4f}\")\n",
        "        print(f\"  Test F1-Score: {tuned_f1:.4f}\")\n",
        "\n",
        "        # Compare with baseline\n",
        "        baseline_f1 = self.results[model_name]['test_f1']\n",
        "        improvement = tuned_f1 - baseline_f1\n",
        "\n",
        "        print(f\"\\nImprovement over baseline: {improvement:.4f}\")\n",
        "        if improvement > 0:\n",
        "            print(\"✅ Tuning improved performance!\")\n",
        "        else:\n",
        "            print(\"⚠️  Tuning did not improve performance\")\n",
        "\n",
        "        return {\n",
        "            'best_params': best_params,\n",
        "            'best_score': best_score,\n",
        "            'tuned_model': tuned_model,\n",
        "            'test_accuracy': tuned_accuracy,\n",
        "            'test_f1': tuned_f1,\n",
        "            'improvement': improvement\n",
        "        }\n",
        "\n",
        "    def feature_importance_analysis(self, model_name=None):\n",
        "        \"\"\"Analyze feature importance for classification models\"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"FEATURE IMPORTANCE ANALYSIS\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        if model_name is None:\n",
        "            # Use best model if available\n",
        "            if self.best_model:\n",
        "                model_name = self.best_model['name']\n",
        "            else:\n",
        "                model_name = 'Random Forest'\n",
        "\n",
        "        if model_name not in self.models:\n",
        "            print(f\"Model {model_name} not found!\")\n",
        "            return None\n",
        "\n",
        "        model = self.models[model_name]\n",
        "\n",
        "        # Check if model has feature_importances_ attribute\n",
        "        if hasattr(model, 'feature_importances_'):\n",
        "            importances = model.feature_importances_\n",
        "\n",
        "            # Create DataFrame\n",
        "            feature_names = [f'Feature_{i}' for i in range(len(importances))]\n",
        "            importance_df = pd.DataFrame({\n",
        "                'feature': feature_names,\n",
        "                'importance': importances\n",
        "            }).sort_values('importance', ascending=False)\n",
        "\n",
        "            # Plot top 20 features\n",
        "            top_n = min(20, len(importance_df))\n",
        "            plt.figure(figsize=(10, 8))\n",
        "            plt.barh(range(top_n), importance_df['importance'].head(top_n), color='steelblue')\n",
        "            plt.yticks(range(top_n), importance_df['feature'].head(top_n))\n",
        "            plt.xlabel('Feature Importance')\n",
        "            plt.title(f'Top {top_n} Feature Importances - {model_name}')\n",
        "            plt.gca().invert_yaxis()\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "            print(f\"\\nTop 10 Most Important Features:\")\n",
        "            print(\"-\" * 50)\n",
        "            for i, (_, row) in enumerate(importance_df.head(10).iterrows(), 1):\n",
        "                print(f\"{i:2}. {row['feature']:20} : {row['importance']:.4f}\")\n",
        "\n",
        "            return importance_df\n",
        "        elif hasattr(model, 'coef_'):\n",
        "            # For linear models like Logistic Regression\n",
        "            importances = np.abs(model.coef_[0])\n",
        "\n",
        "            # Create DataFrame\n",
        "            feature_names = [f'Feature_{i}' for i in range(len(importances))]\n",
        "            importance_df = pd.DataFrame({\n",
        "                'feature': feature_names,\n",
        "                'importance': importances\n",
        "            }).sort_values('importance', ascending=False)\n",
        "\n",
        "            # Plot top 20 features\n",
        "            top_n = min(20, len(importance_df))\n",
        "            plt.figure(figsize=(10, 8))\n",
        "            plt.barh(range(top_n), importance_df['importance'].head(top_n), color='lightcoral')\n",
        "            plt.yticks(range(top_n), importance_df['feature'].head(top_n))\n",
        "            plt.xlabel('Absolute Coefficient Value')\n",
        "            plt.title(f'Top {top_n} Feature Importances - {model_name}')\n",
        "            plt.gca().invert_yaxis()\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "            print(f\"\\nTop 10 Most Important Features (by absolute coefficient):\")\n",
        "            print(\"-\" * 60)\n",
        "            for i, (_, row) in enumerate(importance_df.head(10).iterrows(), 1):\n",
        "                print(f\"{i:2}. {row['feature']:20} : {row['importance']:.4f}\")\n",
        "\n",
        "            return importance_df\n",
        "        else:\n",
        "            print(f\"Model {model_name} does not support feature importance analysis\")\n",
        "            return None\n",
        "\n",
        "    def save_model(self, model_name, filepath):\n",
        "        \"\"\"Save trained model to file\"\"\"\n",
        "        if model_name in self.models:\n",
        "            joblib.dump(self.models[model_name], filepath)\n",
        "            print(f\"✅ Model saved to: {filepath}\")\n",
        "            return True\n",
        "        else:\n",
        "            print(f\"Model {model_name} not found!\")\n",
        "            return False\n",
        "\n",
        "    def generate_classification_report(self):\n",
        "        \"\"\"Generate comprehensive classification report\"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"CLASSIFICATION MODELING REPORT\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        # Train baseline models\n",
        "        self.train_baseline_models()\n",
        "\n",
        "        # Compare models\n",
        "        comparison_df = self.compare_models()\n",
        "\n",
        "        # Plot confusion matrix for best model\n",
        "        if self.best_model:\n",
        "            self.plot_confusion_matrix(self.best_model['name'])\n",
        "\n",
        "        # Plot ROC curves\n",
        "        self.plot_roc_curves()\n",
        "\n",
        "        # Hyperparameter tuning for best model\n",
        "        if self.best_model:\n",
        "            tuning_results = self.hyperparameter_tuning(\n",
        "                model_name=self.best_model['name'],\n",
        "                n_iter=30\n",
        "            )\n",
        "\n",
        "        # Feature importance analysis\n",
        "        importance_df = self.feature_importance_analysis()\n",
        "\n",
        "        # Business impact analysis\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"BUSINESS IMPACT ANALYSIS\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        if self.best_model:\n",
        "            # Calculate business metrics\n",
        "            model = self.best_model['model']\n",
        "            y_pred = model.predict(self.X_test)\n",
        "            cm = confusion_matrix(self.y_test, y_pred)\n",
        "\n",
        "            # Assuming:\n",
        "            # - True Positive: Correctly predicted Won (opportunity captured)\n",
        "            # - False Negative: Predicted Lost but actually Won (missed opportunity)\n",
        "            # - Cost of missed opportunity (example: average deal value)\n",
        "\n",
        "            tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "            print(f\"\\nConfusion Matrix Analysis:\")\n",
        "            print(f\"  True Positives (Correctly predicted Won): {tp}\")\n",
        "            print(f\"  False Negatives (Missed opportunities): {fn}\")\n",
        "            print(f\"  False Positives (False alarms): {fp}\")\n",
        "            print(f\"  True Negatives (Correctly predicted Lost): {tn}\")\n",
        "\n",
        "            # Calculate key business metrics\n",
        "            opportunity_capture_rate = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "            false_alarm_rate = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
        "\n",
        "            print(f\"\\nBusiness Metrics:\")\n",
        "            print(f\"  Opportunity Capture Rate: {opportunity_capture_rate:.2%}\")\n",
        "            print(f\"  False Alarm Rate: {false_alarm_rate:.2%}\")\n",
        "\n",
        "            # Example business impact calculation\n",
        "            avg_deal_value = 100000  # Example average deal value in dollars\n",
        "            missed_opportunity_cost = fn * avg_deal_value\n",
        "            false_alarm_cost = fp * 5000  # Example cost of pursuing false leads\n",
        "\n",
        "            print(f\"\\nEstimated Business Impact (Example):\")\n",
        "            print(f\"  Missed Opportunity Cost: ${missed_opportunity_cost:,.2f}\")\n",
        "            print(f\"  False Alarm Cost: ${false_alarm_cost:,.2f}\")\n",
        "            print(f\"  Total Potential Loss: ${missed_opportunity_cost + false_alarm_cost:,.2f}\")\n",
        "\n",
        "        # Final recommendations\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"FINAL RECOMMENDATIONS\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        if self.best_model:\n",
        "            print(f\"\\n🎯 Recommended Model: {self.best_model['name']}\")\n",
        "            print(f\"   Performance: Accuracy = {self.best_model['metrics']['test_accuracy']:.4f}\")\n",
        "            print(f\"   F1-Score: {self.best_model['metrics'].get('test_f1', 'N/A')}\")\n",
        "\n",
        "            # Check for overfitting\n",
        "            if self.best_model['metrics']['overfit_score'] > 0.1:\n",
        "                print(f\"   ⚠️  Warning: Potential overfitting detected\")\n",
        "                print(f\"      (Train Accuracy - Test Accuracy = {self.best_model['metrics']['overfit_score']:.4f})\")\n",
        "\n",
        "        print(\"\\nNext Steps:\")\n",
        "        print(\"1. Fine-tune model based on business priorities (capture rate vs false alarms)\")\n",
        "        print(\"2. Implement decision threshold adjustment based on cost-benefit analysis\")\n",
        "        print(\"3. Create ensemble of top-performing models\")\n",
        "        print(\"4. Monitor model performance over time with new data\")\n",
        "\n",
        "        return {\n",
        "            'comparison': comparison_df,\n",
        "            'best_model': self.best_model,\n",
        "            'feature_importance': importance_df,\n",
        "            'confusion_matrix': cm if 'cm' in locals() else None\n",
        "        }\n",
        "\n",
        "# Import required metrics\n",
        "from sklearn.metrics import roc_curve, auc, classification_report\n",
        "\n",
        "# Initialize and run classification modeling\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"STARTING CLASSIFICATION MODELING\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "cls_modeler = ClassificationModeler(\n",
        "    X_train_cls_pca, X_test_cls_pca,\n",
        "    y_train_cls_res, y_test_cls\n",
        ")\n",
        "\n",
        "classification_report = cls_modeler.generate_classification_report()\n",
        "\n",
        "# Save the best classification model\n",
        "if cls_modeler.best_model:\n",
        "    cls_modeler.save_model(\n",
        "        cls_modeler.best_model['name'],\n",
        "        'best_classification_model.pkl'\n",
        "    )\n"
      ],
      "metadata": {
        "id": "G_CbG61ugNwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Model Evaluation and Comparison <a name=\"evaluation\"></a>"
      ],
      "metadata": {
        "id": "T5VoAF9sgRWw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================================================\n",
        "# SECTION 8: COMPREHENSIVE MODEL EVALUATION AND COMPARISON\n",
        "# ============================================================================\n",
        "\n",
        "class ModelEvaluator:\n",
        "    \"\"\"Comprehensive evaluation and comparison of all models\"\"\"\n",
        "\n",
        "    def __init__(self, reg_modeler, cls_modeler):\n",
        "        self.reg_modeler = reg_modeler\n",
        "        self.cls_modeler = cls_modeler\n",
        "        self.comparison_results = {}\n",
        "\n",
        "    def compare_regression_models(self):\n",
        "        \"\"\"Detailed comparison of regression models\"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"REGRESSION MODELS COMPREHENSIVE COMPARISON\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        if not hasattr(self.reg_modeler, 'results') or not self.reg_modeler.results:\n",
        "            print(\"No regression results available!\")\n",
        "            return None\n",
        "\n",
        "        # Create detailed comparison DataFrame\n",
        "        reg_comparison = pd.DataFrame(self.reg_modeler.results).T\n",
        "\n",
        "        # Calculate additional metrics\n",
        "        reg_comparison['mse_ratio'] = reg_comparison['test_mse'] / reg_comparison['train_mse']\n",
        "        reg_comparison['rmse_ratio'] = reg_comparison['test_rmse'] / reg_comparison['train_rmse']\n",
        "\n",
        "        # Sort by test R²\n",
        "        reg_comparison = reg_comparison.sort_values('test_r2', ascending=False)\n",
        "\n",
        "        print(\"\\nRegression Models Performance:\")\n",
        "        print(\"-\" * 100)\n",
        "        display_cols = ['test_r2', 'test_rmse', 'test_mae', 'train_r2', 'overfit_score', 'mse_ratio']\n",
        "        print(reg_comparison[display_cols].round(4))\n",
        "\n",
        "        # Visualization\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "        # R² Comparison (Train vs Test)\n",
        "        models = reg_comparison.index\n",
        "        x = np.arange(len(models))\n",
        "        width = 0.35\n",
        "\n",
        "        axes[0, 0].bar(x - width/2, reg_comparison['train_r2'], width, label='Train', color='skyblue')\n",
        "        axes[0, 0].bar(x + width/2, reg_comparison['test_r2'], width, label='Test', color='lightcoral')\n",
        "        axes[0, 0].set_xlabel('Models')\n",
        "        axes[0, 0].set_ylabel('R² Score')\n",
        "        axes[0, 0].set_title('Train vs Test R² Scores')\n",
        "        axes[0, 0].set_xticks(x)\n",
        "        axes[0, 0].set_xticklabels(models, rotation=45, ha='right')\n",
        "        axes[0, 0].legend()\n",
        "        axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "        # Error Metrics Comparison\n",
        "        error_metrics = ['test_rmse', 'test_mae']\n",
        "        colors = ['lightgreen', 'orange']\n",
        "\n",
        "        for idx, metric in enumerate(error_metrics):\n",
        "            axes[0, 1].bar(x + (idx-0.5)*width, reg_comparison[metric], width,\n",
        "                          label=metric.replace('test_', '').upper(), color=colors[idx])\n",
        "\n",
        "        axes[0, 1].set_xlabel('Models')\n",
        "        axes[0, 1].set_ylabel('Error Value')\n",
        "        axes[0, 1].set_title('Error Metrics Comparison')\n",
        "        axes[0, 1].set_xticks(x)\n",
        "        axes[0, 1].set_xticklabels(models, rotation=45, ha='right')\n",
        "        axes[0, 1].legend()\n",
        "        axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "        # Overfitting Analysis\n",
        "        axes[1, 0].bar(x, reg_comparison['overfit_score'], color='purple')\n",
        "        axes[1, 0].axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
        "        axes[1, 0].set_xlabel('Models')\n",
        "        axes[1, 0].set_ylabel('Train R² - Test R²')\n",
        "        axes[1, 0].set_title('Overfitting Analysis')\n",
        "        axes[1, 0].set_xticks(x)\n",
        "        axes[1, 0].set_xticklabels(models, rotation=45, ha='right')\n",
        "        axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "        # Feature Importance Comparison (if available)\n",
        "        axes[1, 1].text(0.5, 0.5, 'Feature Importance\\nAnalysis Complete\\nin Previous Sections',\n",
        "                       ha='center', va='center', transform=axes[1, 1].transAxes,\n",
        "                       fontsize=12, bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "        axes[1, 1].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        self.comparison_results['regression'] = reg_comparison\n",
        "        return reg_comparison\n",
        "\n",
        "    def compare_classification_models(self):\n",
        "        \"\"\"Detailed comparison of classification models\"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"CLASSIFICATION MODELS COMPREHENSIVE COMPARISON\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        if not hasattr(self.cls_modeler, 'results') or not self.cls_modeler.results:\n",
        "            print(\"No classification results available!\")\n",
        "            return None\n",
        "\n",
        "        # Create detailed comparison DataFrame\n",
        "        cls_comparison = pd.DataFrame(self.cls_modeler.results).T\n",
        "\n",
        "        # Sort by test F1 score\n",
        "        if 'test_f1' in cls_comparison.columns:\n",
        "            cls_comparison = cls_comparison.sort_values('test_f1', ascending=False)\n",
        "            sort_metric = 'test_f1'\n",
        "        else:\n",
        "            cls_comparison = cls_comparison.sort_values('test_accuracy', ascending=False)\n",
        "            sort_metric = 'test_accuracy'\n",
        "\n",
        "        print(f\"\\nClassification Models Performance (sorted by {sort_metric}):\")\n",
        "        print(\"-\" * 100)\n",
        "        display_cols = ['test_accuracy', 'test_f1', 'test_precision', 'test_recall',\n",
        "                       'roc_auc', 'overfit_score']\n",
        "        display_cols = [col for col in display_cols if col in cls_comparison.columns]\n",
        "        print(cls_comparison[display_cols].round(4))\n",
        "\n",
        "        # Visualization\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "        models = cls_comparison.index\n",
        "        x = np.arange(len(models))\n",
        "        width = 0.35\n",
        "\n",
        "        # Accuracy Comparison (Train vs Test)\n",
        "        if 'train_accuracy' in cls_comparison.columns and 'test_accuracy' in cls_comparison.columns:\n",
        "            axes[0, 0].bar(x - width/2, cls_comparison['train_accuracy'], width,\n",
        "                          label='Train', color='skyblue')\n",
        "            axes[0, 0].bar(x + width/2, cls_comparison['test_accuracy'], width,\n",
        "                          label='Test', color='lightcoral')\n",
        "            axes[0, 0].set_xlabel('Models')\n",
        "            axes[0, 0].set_ylabel('Accuracy')\n",
        "            axes[0, 0].set_title('Train vs Test Accuracy')\n",
        "            axes[0, 0].set_xticks(x)\n",
        "            axes[0, 0].set_xticklabels(models, rotation=45, ha='right')\n",
        "            axes[0, 0].legend()\n",
        "            axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "        # F1 Score Comparison\n",
        "        if 'test_f1' in cls_comparison.columns:\n",
        "            axes[0, 1].bar(x, cls_comparison['test_f1'], width, color='lightgreen')\n",
        "            axes[0, 1].set_xlabel('Models')\n",
        "            axes[0, 1].set_ylabel('F1 Score')\n",
        "            axes[0, 1].set_title('F1 Scores Comparison')\n",
        "            axes[0, 1].set_xticks(x)\n",
        "            axes[0, 1].set_xticklabels(models, rotation=45, ha='right')\n",
        "            axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "        # ROC-AUC Scores\n",
        "        if 'roc_auc' in cls_comparison.columns:\n",
        "            axes[1, 0].bar(x, cls_comparison['roc_auc'], width, color='orange')\n",
        "            axes[1, 0].axhline(y=0.5, color='red', linestyle='--', alpha=0.5, label='Random')\n",
        "            axes[1, 0].set_xlabel('Models')\n",
        "            axes[1, 0].set_ylabel('ROC-AUC Score')\n",
        "            axes[1, 0].set_title('ROC-AUC Scores Comparison')\n",
        "            axes[1, 0].set_xticks(x)\n",
        "            axes[1, 0].set_xticklabels(models, rotation=45, ha='right')\n",
        "            axes[1, 0].legend()\n",
        "            axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "        # Overfitting Analysis\n",
        "        if 'overfit_score' in cls_comparison.columns:\n",
        "            axes[1, 1].bar(x, cls_comparison['overfit_score'], width, color='purple')\n",
        "            axes[1, 1].axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
        "            axes[1, 1].set_xlabel('Models')\n",
        "            axes[1, 1].set_ylabel('Train - Test Accuracy')\n",
        "            axes[1, 1].set_title('Overfitting Analysis')\n",
        "            axes[1, 1].set_xticks(x)\n",
        "            axes[1, 1].set_xticklabels(models, rotation=45, ha='right')\n",
        "            axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        self.comparison_results['classification'] = cls_comparison\n",
        "        return cls_comparison\n",
        "\n",
        "    def generate_comprehensive_report(self):\n",
        "        \"\"\"Generate comprehensive report comparing both tasks\"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"COMPREHENSIVE MODEL EVALUATION REPORT\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        # Compare regression models\n",
        "        reg_results = self.compare_regression_models()\n",
        "\n",
        "        # Compare classification models\n",
        "        cls_results = self.compare_classification_models()\n",
        "\n",
        "        # Overall assessment\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"OVERALL ASSESSMENT\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        print(\"\\n🎯 REGRESSION TASK (Selling Price Prediction):\")\n",
        "        if reg_results is not None and not reg_results.empty:\n",
        "            best_reg_model = reg_results.index[0]\n",
        "            best_reg_r2 = reg_results.loc[best_reg_model, 'test_r2']\n",
        "            best_reg_rmse = reg_results.loc[best_reg_model, 'test_rmse']\n",
        "\n",
        "            print(f\"  Best Model: {best_reg_model}\")\n",
        "            print(f\"  R² Score: {best_reg_r2:.4f}\")\n",
        "            print(f\"  RMSE: {best_reg_rmse:.4f}\")\n",
        "\n",
        "            if best_reg_r2 > 0.8:\n",
        "                print(\"  ✅ Excellent performance!\")\n",
        "            elif best_reg_r2 > 0.6:\n",
        "                print(\"  👍 Good performance\")\n",
        "            elif best_reg_r2 > 0.4:\n",
        "                print(\"  ⚠️  Acceptable performance\")\n",
        "            else:\n",
        "                print(\"  ❌ Needs improvement\")\n",
        "\n",
        "        print(\"\\n🎯 CLASSIFICATION TASK (Lead Outcome Prediction):\")\n",
        "        if cls_results is not None and not cls_results.empty:\n",
        "            best_cls_model = cls_results.index[0]\n",
        "            best_cls_accuracy = cls_results.loc[best_cls_model, 'test_accuracy']\n",
        "\n",
        "            # Try to get F1 score\n",
        "            if 'test_f1' in cls_results.columns:\n",
        "                best_cls_f1 = cls_results.loc[best_cls_model, 'test_f1']\n",
        "                print(f\"  Best Model: {best_cls_model}\")\n",
        "                print(f\"  Accuracy: {best_cls_accuracy:.4f}\")\n",
        "                print(f\"  F1-Score: {best_cls_f1:.4f}\")\n",
        "            else:\n",
        "                print(f\"  Best Model: {best_cls_model}\")\n",
        "                print(f\"  Accuracy: {best_cls_accuracy:.4f}\")\n",
        "\n",
        "            if best_cls_accuracy > 0.9:\n",
        "                print(\"  ✅ Excellent performance!\")\n",
        "            elif best_cls_accuracy > 0.8:\n",
        "                print(\"  👍 Good performance\")\n",
        "            elif best_cls_accuracy > 0.7:\n",
        "                print(\"  ⚠️  Acceptable performance\")\n",
        "            else:\n",
        "                print(\"  ❌ Needs improvement\")\n",
        "\n",
        "        # Recommendations for improvement\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"RECOMMENDATIONS FOR IMPROVEMENT\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        print(\"\\n1. DATA QUALITY:\")\n",
        "        print(\"   - Collect more recent and diverse data\")\n",
        "        print(\"   - Address remaining data quality issues\")\n",
        "        print(\"   - Implement data validation rules\")\n",
        "\n",
        "        print(\"\\n2. FEATURE ENGINEERING:\")\n",
        "        print(\"   - Create more domain-specific features\")\n",
        "        print(\"   - Experiment with different encoding strategies\")\n",
        "        print(\"   - Consider feature interactions\")\n",
        "\n",
        "        print(\"\\n3. MODELING:\")\n",
        "        print(\"   - Try ensemble methods (Stacking, Voting)\")\n",
        "        print(\"   - Experiment with deep learning approaches\")\n",
        "        print(\"   - Implement cross-validation more rigorously\")\n",
        "\n",
        "        print(\"\\n4. DEPLOYMENT READINESS:\")\n",
        "        print(\"   - Create API endpoints for model serving\")\n",
        "        print(\"   - Implement model monitoring\")\n",
        "        print(\"   - Set up automated retraining pipeline\")\n",
        "\n",
        "        print(\"\\n5. BUSINESS INTEGRATION:\")\n",
        "        print(\"   - Align model thresholds with business costs\")\n",
        "        print(\"   - Create dashboard for business users\")\n",
        "        print(\"   - Establish feedback loop for model improvement\")\n",
        "\n",
        "        return {\n",
        "            'regression_results': reg_results,\n",
        "            'classification_results': cls_results\n",
        "        }\n",
        "\n",
        "# Run comprehensive evaluation\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"STARTING COMPREHENSIVE MODEL EVALUATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "evaluator = ModelEvaluator(reg_modeler, cls_modeler)\n",
        "comprehensive_report = evaluator.generate_comprehensive_report()\n"
      ],
      "metadata": {
        "id": "_EsX9oShhMDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Conclusion and Recommendations <a name=\"conclusion\"></a>"
      ],
      "metadata": {
        "id": "0Tk9sDtohPrF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================================================\n",
        "# SECTION 9: CONCLUSION AND RECOMMENDATIONS\n",
        "# ============================================================================\n",
        "\n",
        "class ProjectConclusion:\n",
        "    \"\"\"Generate final conclusion and recommendations\"\"\"\n",
        "\n",
        "    def __init__(self, data_info, cleaning_summary, eda_insights,\n",
        "                 feature_summary, data_summary, reg_report, cls_report):\n",
        "        self.data_info = data_info\n",
        "        self.cleaning_summary = cleaning_summary\n",
        "        self.eda_insights = eda_insights\n",
        "        self.feature_summary = feature_summary\n",
        "        self.data_summary = data_summary\n",
        "        self.reg_report = reg_report\n",
        "        self.cls_report = cls_report\n",
        "\n",
        "    def generate_executive_summary(self):\n",
        "        \"\"\"Generate executive summary for stakeholders\"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"EXECUTIVE SUMMARY\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        print(\"\\n📊 PROJECT OVERVIEW:\")\n",
        "        print(\"-\" * 40)\n",
        "        print(\"This project developed machine learning models for copper industry analytics\")\n",
        "        print(\"with two main objectives:\")\n",
        "        print(\"1. Predict selling prices (Regression)\")\n",
        "        print(\"2. Predict lead outcomes - Won/Lost (Classification)\")\n",
        "\n",
        "        print(\"\\n🎯 KEY ACHIEVEMENTS:\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        # Regression achievements\n",
        "        if self.reg_report and 'best_model' in self.reg_report:\n",
        "            reg_model = self.reg_report['best_model']\n",
        "            print(f\"\\n1. REGRESSION (Price Prediction):\")\n",
        "            print(f\"   • Best Model: {reg_model['name']}\")\n",
        "            print(f\"   • R² Score: {reg_model['metrics']['test_r2']:.4f}\")\n",
        "            print(f\"   • Prediction Error (RMSE): {reg_model['metrics']['test_rmse']:.4f}\")\n",
        "\n",
        "        # Classification achievements\n",
        "        if self.cls_report and 'best_model' in self.cls_report:\n",
        "            cls_model = self.cls_report['best_model']\n",
        "            print(f\"\\n2. CLASSIFICATION (Lead Prediction):\")\n",
        "            print(f\"   • Best Model: {cls_model['name']}\")\n",
        "            print(f\"   • Accuracy: {cls_model['metrics']['test_accuracy']:.4f}\")\n",
        "            if 'test_f1' in cls_model['metrics']:\n",
        "                print(f\"   • F1-Score: {cls_model['metrics']['test_f1']:.4f}\")\n",
        "\n",
        "        print(\"\\n🔧 TECHNICAL APPROACH:\")\n",
        "        print(\"-\" * 40)\n",
        "        print(\"• Comprehensive data cleaning and preprocessing\")\n",
        "        print(\"• Advanced feature engineering and transformation\")\n",
        "        print(\"• Multiple machine learning algorithms tested\")\n",
        "        print(\"• Hyperparameter optimization for best models\")\n",
        "        print(\"• Rigorous evaluation using multiple metrics\")\n",
        "\n",
        "        print(\"\\n💼 BUSINESS VALUE:\")\n",
        "        print(\"-\" * 40)\n",
        "        print(\"• Improved pricing strategies through accurate predictions\")\n",
        "        print(\"• Better lead qualification and prioritization\")\n",
        "        print(\"• Data-driven decision making\")\n",
        "        print(\"• Potential for increased revenue and reduced costs\")\n",
        "\n",
        "    def generate_technical_conclusion(self):\n",
        "        \"\"\"Generate technical conclusion for data scientists\"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"TECHNICAL CONCLUSION\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        print(\"\\n📈 DATA PROCESSING SUMMARY:\")\n",
        "        print(\"-\" * 40)\n",
        "        if self.cleaning_summary:\n",
        "            print(f\"• Initial data shape: {self.cleaning_summary['initial_shape']}\")\n",
        "            print(f\"• Final data shape: {self.cleaning_summary['final_shape']}\")\n",
        "            print(f\"• Cleaning steps: {len(self.cleaning_summary['steps'])}\")\n",
        "\n",
        "        if self.feature_summary:\n",
        "            print(f\"• Final features: {self.feature_summary['final_shape'][1]}\")\n",
        "            print(f\"• Transformations applied: {len(self.feature_summary['transformations'])}\")\n",
        "\n",
        "        print(\"\\n🤖 MODEL PERFORMANCE INSIGHTS:\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        # Regression insights\n",
        "        print(\"\\nREGRESSION MODELS:\")\n",
        "        if self.reg_report and 'comparison' in self.reg_report:\n",
        "            reg_comp = self.reg_report['comparison']\n",
        "            if not reg_comp.empty:\n",
        "                print(f\"• Best performing: {reg_comp.index[0]}\")\n",
        "                print(f\"• Average R² across models: {reg_comp['test_r2'].mean():.4f}\")\n",
        "                print(f\"• Range of R² scores: [{reg_comp['test_r2'].min():.4f}, {reg_comp['test_r2'].max():.4f}]\")\n",
        "\n",
        "        # Classification insights\n",
        "        print(\"\\nCLASSIFICATION MODELS:\")\n",
        "        if self.cls_report and 'comparison' in self.cls_report:\n",
        "            cls_comp = self.cls_report['comparison']\n",
        "            if not cls_comp.empty:\n",
        "                print(f\"• Best performing: {cls_comp.index[0]}\")\n",
        "                print(f\"• Average accuracy: {cls_comp['test_accuracy'].mean():.4f}\")\n",
        "                print(f\"• Average F1-Score: {cls_comp['test_f1'].mean():.4f if 'test_f1' in cls_comp.columns else 'N/A'}\")\n",
        "\n",
        "        print(\"\\n⚡ KEY CHALLENGES AND SOLUTIONS:\")\n",
        "        print(\"-\" * 40)\n",
        "        print(\"1. Data Quality:\")\n",
        "        print(\"   • Challenge: Missing values and outliers\")\n",
        "        print(\"   • Solution: Comprehensive cleaning pipeline with multiple imputation methods\")\n",
        "\n",
        "        print(\"\\n2. Feature Engineering:\")\n",
        "        print(\"   • Challenge: Skewed distributions and categorical encoding\")\n",
        "        print(\"   • Solution: Transformations (log, Box-Cox) and target encoding\")\n",
        "\n",
        "        print(\"\\n3. Model Selection:\")\n",
        "        print(\"   • Challenge: Choosing between multiple algorithms\")\n",
        "        print(\"   • Solution: Comparative analysis with multiple metrics\")\n",
        "\n",
        "        print(\"\\n4. Class Imbalance:\")\n",
        "        print(\"   • Challenge: Uneven distribution of lead outcomes\")\n",
        "        print(\"   • Solution: SMOTE oversampling and class weights\")\n",
        "\n",
        "    def generate_recommendations(self):\n",
        "        \"\"\"Generate actionable recommendations\"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"ACTIONABLE RECOMMENDATIONS\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        print(\"\\n🎯 IMMEDIATE ACTIONS (Next 1-2 Weeks):\")\n",
        "        print(\"-\" * 40)\n",
        "        print(\"1. Deploy best regression model for price prediction\")\n",
        "        print(\"2. Implement classification model for lead scoring\")\n",
        "        print(\"3. Create dashboards for business users\")\n",
        "        print(\"4. Establish model monitoring framework\")\n",
        "\n",
        "        print(\"\\n📊 SHORT-TERM IMPROVEMENTS (1-3 Months):\")\n",
        "        print(\"-\" * 40)\n",
        "        print(\"1. Collect more recent and diverse data\")\n",
        "        print(\"2. Implement A/B testing for model variants\")\n",
        "        print(\"3. Add more domain-specific features\")\n",
        "        print(\"4. Optimize model performance based on business feedback\")\n",
        "\n",
        "        print(\"\\n🚀 LONG-TERM STRATEGY (3-12 Months):\")\n",
        "        print(\"-\" * 40)\n",
        "        print(\"1. Build real-time prediction pipeline\")\n",
        "        print(\"2. Integrate with CRM and ERP systems\")\n",
        "        print(\"3. Develop ensemble models for improved accuracy\")\n",
        "        print(\"4. Create automated retraining pipeline\")\n",
        "        print(\"5. Expand to other predictive analytics use cases\")\n",
        "\n",
        "        print(\"\\n🔬 AREAS FOR FURTHER RESEARCH:\")\n",
        "        print(\"-\" * 40)\n",
        "        print(\"1. Deep learning approaches for time series prediction\")\n",
        "        print(\"2. Natural language processing for customer notes\")\n",
        "        print(\"3. Reinforcement learning for dynamic pricing\")\n",
        "        print(\"4. Anomaly detection for unusual transactions\")\n",
        "\n",
        "        print(\"\\n📈 SUCCESS METRICS TO TRACK:\")\n",
        "        print(\"-\" * 40)\n",
        "        print(\"• Model accuracy and stability over time\")\n",
        "        print(\"• Business impact (revenue increase, cost reduction)\")\n",
        "        print(\"• User adoption and satisfaction\")\n",
        "        print(\"• Return on investment (ROI)\")\n",
        "\n",
        "    def save_project_artifacts(self):\n",
        "        \"\"\"Save all project artifacts\"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"SAVING PROJECT ARTIFACTS\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        artifacts = {\n",
        "            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "            'data_info': self.data_info,\n",
        "            'cleaning_summary': self.cleaning_summary,\n",
        "            'eda_insights': self.eda_insights,\n",
        "            'feature_summary': self.feature_summary,\n",
        "            'data_summary': self.data_summary,\n",
        "            'regression_report': self.reg_report,\n",
        "            'classification_report': self.cls_report\n",
        "        }\n",
        "\n",
        "        # Save to JSON\n",
        "        with open('project_artifacts.json', 'w') as f:\n",
        "            json.dump(artifacts, f, indent=4, default=str)\n",
        "\n",
        "        print(\"✅ Project artifacts saved to 'project_artifacts.json'\")\n",
        "\n",
        "        # Save cleaned data\n",
        "        df.to_csv('cleaned_copper_data.csv', index=False)\n",
        "        print(\"✅ Cleaned data saved to 'cleaned_copper_data.csv'\")\n",
        "\n",
        "        # Save models if available\n",
        "        if hasattr(reg_modeler, 'best_model') and reg_modeler.best_model:\n",
        "            joblib.dump(reg_modeler.best_model['model'], 'final_regression_model.pkl')\n",
        "            print(\"✅ Final regression model saved\")\n",
        "\n",
        "        if hasattr(cls_modeler, 'best_model') and cls_modeler.best_model:\n",
        "            joblib.dump(cls_modeler.best_model['model'], 'final_classification_model.pkl')\n",
        "            print(\"✅ Final classification model saved\")\n",
        "\n",
        "        # Generate markdown report\n",
        "        self.generate_markdown_report()\n",
        "\n",
        "    def generate_markdown_report(self):\n",
        "        \"\"\"Generate markdown report of the project\"\"\"\n",
        "        report_content = f\"\"\"# Copper Industry Analytics: Complete Project Report\n"
      ],
      "metadata": {
        "id": "aZCuzZTAhY-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Project Timeline"
      ],
      "metadata": {
        "id": "hpXWy5U7h1pf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## Executive Summary\n",
        "This project successfully developed machine learning models for predicting copper selling prices and lead outcomes.\n",
        "\n",
        "## Project Timeline\n",
        "- **Start Date**: {datetime.now().strftime('%Y-%m-%d')}\n",
        "- **Status**: Completed\n",
        "\n",
        "## Key Findings\n",
        "\n",
        "### Data Characteristics\n",
        "- Initial dataset: {self.cleaning_summary['initial_shape']}\n",
        "- Final dataset: {self.cleaning_summary['final_shape']}\n",
        "- Features engineered: {self.feature_summary['feature_counts']['numerical'] + self.feature_summary['feature_counts']['categorical']}\n",
        "\n",
        "### Model Performance\n",
        "\n",
        "#### Regression (Price Prediction)\n",
        "- Best Model: {self.reg_report['best_model']['name'] if self.reg_report and 'best_model' in self.reg_report else 'N/A'}\n",
        "- R² Score: {self.reg_report['best_model']['metrics']['test_r2']:.4f if self.reg_report and 'best_model' in self.reg_report else 'N/A'}\n",
        "- RMSE: {self.reg_report['best_model']['metrics']['test_rmse']:.4f if self.reg_report and 'best_model' in self.reg_report else 'N/A'}\n",
        "\n",
        "#### Classification (Lead Prediction)\n",
        "- Best Model: {self.cls_report['best_model']['name'] if self.cls_report and 'best_model' in self.cls_report else 'N/A'}\n",
        "- Accuracy: {self.cls_report['best_model']['metrics']['test_accuracy']:.4f if self.cls_report and 'best_model' in self.cls_report else 'N/A'}\n",
        "\n",
        "## Recommendations\n",
        "1. Deploy regression model for price optimization\n",
        "2. Use classification model for lead scoring\n",
        "3. Implement monitoring and retraining pipeline\n",
        "\n",
        "## Next Steps\n",
        "- Production deployment\n",
        "- Continuous improvement\n",
        "- Business integration\n",
        "\n",
        "---\n",
        "*Report generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*\n",
        "\n",
        "\n",
        "        with open('project_report.md', 'w') as f:\n",
        "            f.write(report_content)\n",
        "\n",
        "        print(\"✅ Markdown report saved to 'project_report.md'\")\n",
        "\n",
        "    def generate_final_conclusion(self):\n",
        "        \"\"\"Generate final comprehensive conclusion\"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"FINAL PROJECT CONCLUSION\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        self.generate_executive_summary()\n",
        "        self.generate_technical_conclusion()\n",
        "        self.generate_recommendations()\n",
        "        self.save_project_artifacts()\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"🎉 PROJECT COMPLETED SUCCESSFULLY! 🎉\")\n",
        "        print(\"=\"*80)\n",
        "        print(\"\\nAll analyses completed, models trained, and artifacts saved.\")\n",
        "        print(\"The project is ready for deployment and business integration.\")\n",
        "\n",
        "        return {\n",
        "            'status': 'completed',\n",
        "            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "            'artifacts_saved': True\n",
        "        }\n",
        "\n",
        "# Generate final conclusion\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"GENERATING FINAL CONCLUSION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "conclusion = ProjectConclusion(\n",
        "    data_info=data_info if 'data_info' in locals() else {},\n",
        "    cleaning_summary=cleaning_summary if 'cleaning_summary' in locals() else {},\n",
        "    eda_insights=eda_insights if 'eda_insights' in locals() else {},\n",
        "    feature_summary=feature_summary if 'feature_summary' in locals() else {},\n",
        "    data_summary=data_summary if 'data_summary' in locals() else {},\n",
        "    reg_report=regression_report if 'regression_report' in locals() else {},\n",
        "    cls_report=classification_report if 'classification_report' in locals() else {}\n",
        ")\n",
        "\n",
        "final_result = conclusion.generate_final_conclusion()\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PROJECT COMPLETE - SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\"\"\n",
        "📊 DATA PROCESSING:\n",
        "• Initial data: {cleaning_summary['initial_shape']}\n",
        "• Cleaned data: {cleaning_summary['final_shape']}\n",
        "• Features created: {feature_summary['feature_counts']['numerical'] + feature_summary['feature_counts']['categorical']}\n",
        "\n",
        "🤖 MODELS TRAINED:\n",
        "• Regression models: {len(reg_modeler.models) if hasattr(reg_modeler, 'models') else 0}\n",
        "• Classification models: {len(cls_modeler.models) if hasattr(cls_modeler, 'models') else 0}\n",
        "\n",
        "🏆 BEST PERFORMERS:\n",
        "• Price Prediction: {reg_modeler.best_model['name'] if hasattr(reg_modeler, 'best_model') and reg_modeler.best_model else 'N/A'}\n",
        "• Lead Prediction: {cls_modeler.best_model['name'] if hasattr(cls_modeler, 'best_model') and cls_modeler.best_model else 'N/A'}\n",
        "\n",
        "💾 ARTIFACTS SAVED:\n",
        "• Cleaned data: cleaned_copper_data.csv\n",
        "• Project report: project_report.md\n",
        "• Models: final_regression_model.pkl, final_classification_model.pkl\n",
        "• Full artifacts: project_artifacts.json\n",
        "\n",
        "✅ Ready for deployment and business integration!\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "id": "SSA1X2vchqWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "\n",
        "This complete Jupyter notebook provides:\n",
        "\n",
        "1. **Comprehensive data analysis** from loading to preprocessing\n",
        "2. **Detailed EDA** with visualizations and insights\n",
        "3. **Feature engineering** with transformations and encoding\n",
        "4. **Machine learning modeling** for both regression and classification\n",
        "5. **Model evaluation** with comprehensive metrics\n",
        "6. **Business insights** and recommendations\n",
        "7. **Production-ready artifacts** and reports\n",
        "\n",
        "The notebook is organized, modular, and includes proper documentation throughout. It can be run end-to-end or section by section based on your needs."
      ],
      "metadata": {
        "id": "EE7NRvq8jhCN"
      }
    }
  ]
}